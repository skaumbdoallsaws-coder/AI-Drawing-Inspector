{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AI Engineering Drawing Inspector (Single File)\n\nStreamlined inspector for checking one drawing at a time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 1A: Install Dependencies\n",
        "# ============================================================\n",
        "!pip install -q transformers accelerate\n",
        "!pip install -q qwen-vl-utils\n",
        "!pip install -q pdf2image\n",
        "!pip install -q faiss-cpu sentence-transformers\n",
        "!pip install -q bitsandbytes\n",
        "!apt-get install -y poppler-utils > /dev/null 2>&1\n",
        "\n",
        "# Production Pipeline Dependencies\n",
        "!pip install -q pymupdf opencv-python-headless\n",
        "\n",
        "# Tesseract OCR (replaces PaddleOCR - more stable)\n",
        "!sudo apt-get install -y tesseract-ocr > /dev/null 2>&1\n",
        "!pip install -q pytesseract\n",
        "\n",
        "print(\"✅ All packages installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 1B: Import Libraries\n",
        "# ============================================================\n",
        "import os\n",
        "import json\n",
        "import re\n",
        "import pickle\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from pdf2image import convert_from_path\n",
        "from PIL import Image\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "# Production Pipeline Imports\n",
        "import fitz  # PyMuPDF\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Tuple, Dict, Any\n",
        "\n",
        "# Tesseract OCR\n",
        "import pytesseract\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 2: Load Qwen2-VL Model (4-bit Quantized)\n",
        "# ============================================================\n",
        "import torch\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig\n",
        "\n",
        "MODEL_ID = \"Qwen/Qwen2-VL-72B-Instruct\"\n",
        "\n",
        "print(f\"Loading {MODEL_ID} in 4-bit (NF4)...\")\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_use_double_quant=True\n",
        ")\n",
        "\n",
        "model = Qwen2VLForConditionalGeneration.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=bnb_config,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "\n",
        "print(\"✅ Qwen2-VL-72B (4-bit) Loaded Successfully!\")\n",
        "print(f\"Memory Footprint: {model.get_memory_footprint() / 1e9:.2f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Load Context Databases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 3A: Upload Configuration Files\n",
        "# ============================================================\n",
        "import os\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "\n",
        "MAPPING_FILE = \"400S_file_part_mapping.json\"\n",
        "STRUCTURE_FILE = \"400S_detailed_structure_fixed.json\"\n",
        "RAG_INDEX_FILE = \"asme_visual_index.pkl\"\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"STEP 1: Upload Configuration Files\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "def locate_file(filename):\n",
        "    if os.path.exists(filename):\n",
        "        return os.path.abspath(filename)\n",
        "    nested_path = os.path.join(\"rag_data\", filename)\n",
        "    if os.path.exists(nested_path):\n",
        "        return os.path.abspath(nested_path)\n",
        "    return None\n",
        "\n",
        "FILE_MAPPING_PATH = locate_file(MAPPING_FILE)\n",
        "STRUCTURE_PATH = locate_file(STRUCTURE_FILE)\n",
        "RAG_INDEX_PATH = locate_file(RAG_INDEX_FILE)\n",
        "\n",
        "missing_files = []\n",
        "if not FILE_MAPPING_PATH:\n",
        "    missing_files.append(MAPPING_FILE)\n",
        "if not STRUCTURE_PATH:\n",
        "    missing_files.append(STRUCTURE_FILE)\n",
        "if not RAG_INDEX_PATH:\n",
        "    missing_files.append(RAG_INDEX_FILE)\n",
        "\n",
        "if missing_files:\n",
        "    print(f\"\\nMissing files: {', '.join(missing_files)}\")\n",
        "    print(\"\\nPlease upload the required files (or a ZIP containing them):\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded:\n",
        "        if filename.lower().endswith('.zip'):\n",
        "            print(f\"\\nExtracting {filename}...\")\n",
        "            with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
        "                zip_ref.extractall(\"rag_data\")\n",
        "            print(\"Extraction complete.\")\n",
        "            break\n",
        "\n",
        "    FILE_MAPPING_PATH = locate_file(MAPPING_FILE) or os.path.abspath(MAPPING_FILE)\n",
        "    STRUCTURE_PATH = locate_file(STRUCTURE_FILE) or os.path.abspath(STRUCTURE_FILE)\n",
        "    RAG_INDEX_PATH = locate_file(RAG_INDEX_FILE)\n",
        "\n",
        "if FILE_MAPPING_PATH:\n",
        "    DATA_DIR = os.path.dirname(FILE_MAPPING_PATH)\n",
        "else:\n",
        "    DATA_DIR = \"/content\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"FILE STATUS:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"File Mapping:  {'✅ OK' if FILE_MAPPING_PATH and os.path.exists(FILE_MAPPING_PATH) else '❌ MISSING'}\")\n",
        "print(f\"Structure:     {'✅ OK' if STRUCTURE_PATH and os.path.exists(STRUCTURE_PATH) else '❌ MISSING'}\")\n",
        "print(f\"RAG Index:     {'✅ OK' if RAG_INDEX_PATH and os.path.exists(RAG_INDEX_PATH) else '⚠️ MISSING'}\")\n",
        "print(f\"\\nData directory: {DATA_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 3B: Load Part Context Databases\n",
        "# ============================================================\n",
        "\n",
        "def normalize_pn(pn):\n",
        "    \"\"\"Normalize part number for lookup.\"\"\"\n",
        "    return re.sub(r'[-\\s]', '', str(pn)).lower()\n",
        "\n",
        "def load_context_databases():\n",
        "    \"\"\"Load and build all context databases.\"\"\"\n",
        "    print(\"Loading file mapping...\")\n",
        "    with open(FILE_MAPPING_PATH, 'r') as f:\n",
        "        file_mapping_list = json.load(f)\n",
        "\n",
        "    filename_to_pn = {}\n",
        "    for entry in file_mapping_list:\n",
        "        filename = entry['file']\n",
        "        pn = entry['pn']\n",
        "        if pn:\n",
        "            filename_to_pn[filename] = pn\n",
        "            filename_to_pn[filename + '.pdf'] = pn\n",
        "            filename_to_pn[filename + '.PDF'] = pn\n",
        "\n",
        "    print(f\"  Loaded {len(file_mapping_list)} file mappings\")\n",
        "\n",
        "    print(\"Loading part structure...\")\n",
        "    with open(STRUCTURE_PATH, 'r') as f:\n",
        "        structure_data = json.load(f)\n",
        "\n",
        "    print(\"Building part context database...\")\n",
        "    part_context_db = {}\n",
        "\n",
        "    for assembly_name, parts_list in structure_data.items():\n",
        "        for part in parts_list:\n",
        "            pn = part['pn']\n",
        "            desc = part['desc']\n",
        "\n",
        "            siblings_list = []\n",
        "            siblings_pns = []\n",
        "\n",
        "            for p_sibling in parts_list:\n",
        "                if p_sibling['pn'] != pn:\n",
        "                    safe_desc = str(p_sibling['desc']).replace('\"', \"'\")\n",
        "                    siblings_list.append(f\"{p_sibling['pn']} ({safe_desc})\")\n",
        "                    siblings_pns.append(p_sibling['pn'])\n",
        "\n",
        "            siblings_str = \"; \".join(siblings_list[:12])\n",
        "            if len(siblings_list) > 12:\n",
        "                siblings_str += f\"... and {len(siblings_list) - 12} more\"\n",
        "\n",
        "            lookup_key = normalize_pn(pn)\n",
        "\n",
        "            part_context_db[lookup_key] = {\n",
        "                'pn': pn,\n",
        "                'description': desc,\n",
        "                'assembly': assembly_name,\n",
        "                'siblings': siblings_str,\n",
        "                'siblings_list': siblings_pns\n",
        "            }\n",
        "            part_context_db[pn] = part_context_db[lookup_key]\n",
        "\n",
        "    print(f\"  Built context for {len(part_context_db) // 2} unique parts\")\n",
        "    return filename_to_pn, part_context_db\n",
        "\n",
        "filename_to_pn, part_context_db = load_context_databases()\n",
        "print(\"\\n✅ Context databases loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 3C: Initialize Tesseract OCR\n",
        "# ============================================================\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import re\n",
        "\n",
        "print(\"Loading Tesseract OCR Engine...\")\n",
        "\n",
        "def get_drawing_text_ocr(image_input):\n",
        "    \"\"\"\n",
        "    Runs Tesseract OCR on the drawing and returns a clean list of found text.\n",
        "    Uses PSM 11 (Sparse Text) mode which is best for engineering drawings.\n",
        "\n",
        "    Args:\n",
        "        image_input: PIL Image or numpy array\n",
        "\n",
        "    Returns:\n",
        "        List of unique text strings found\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert numpy array to PIL Image if needed\n",
        "        if isinstance(image_input, np.ndarray):\n",
        "            img = Image.fromarray(image_input)\n",
        "        else:\n",
        "            img = image_input\n",
        "\n",
        "        # Run Tesseract with sparse text mode (PSM 11)\n",
        "        # PSM 11: Sparse text - Find as much text as possible in no particular order\n",
        "        raw_text = pytesseract.image_to_string(img, config='--psm 11')\n",
        "\n",
        "        # Split by newlines and clean\n",
        "        lines = raw_text.split('\\n')\n",
        "\n",
        "        text_set = set()\n",
        "        for line in lines:\n",
        "            # Strip whitespace\n",
        "            cleaned = line.strip()\n",
        "\n",
        "            # Skip empty lines\n",
        "            if not cleaned:\n",
        "                continue\n",
        "\n",
        "            # Skip garbage (less than 2 alphanumeric characters)\n",
        "            alphanumeric_count = sum(1 for c in cleaned if c.isalnum())\n",
        "            if alphanumeric_count < 2:\n",
        "                continue\n",
        "\n",
        "            # Normalize engineering symbols\n",
        "            cleaned = cleaned.replace(\"Ø\", \"DIA \")\n",
        "            cleaned = cleaned.replace(\"ø\", \"DIA \")\n",
        "\n",
        "            text_set.add(cleaned)\n",
        "\n",
        "        return sorted(list(text_set))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ OCR Warning: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"✅ Tesseract OCR Engine Ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 3E: Load RAG Index & Visual Database\n",
        "# ============================================================\n",
        "import os\n",
        "import pickle\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "\n",
        "rag_data = []\n",
        "rag_embeddings = None\n",
        "rag_available = False\n",
        "RAG_IMAGE_DIR = None\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"RAG SYSTEM SETUP\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\n[STEP 1/3] Loading CLIP model...\")\n",
        "search_model = SentenceTransformer('clip-ViT-B-32')\n",
        "print(\"  ✅ CLIP model loaded!\")\n",
        "\n",
        "print(\"\\n[STEP 2/3] Loading RAG Index...\")\n",
        "index_loaded = False\n",
        "\n",
        "# Check multiple locations for the index file\n",
        "index_locations = [\n",
        "    \"/content/asme_visual_index.pkl\",\n",
        "    \"/content/rag_data/asme_visual_index.pkl\",\n",
        "    \"asme_visual_index.pkl\",\n",
        "]\n",
        "if 'RAG_INDEX_PATH' in dir() and RAG_INDEX_PATH:\n",
        "    index_locations.insert(0, RAG_INDEX_PATH)\n",
        "\n",
        "for idx_path in index_locations:\n",
        "    if idx_path and os.path.exists(idx_path):\n",
        "        print(f\"  ✅ Found: {idx_path}\")\n",
        "        with open(idx_path, 'rb') as f:\n",
        "            rag_data = pickle.load(f)\n",
        "        RAG_INDEX_PATH = idx_path\n",
        "        index_loaded = True\n",
        "        break\n",
        "\n",
        "if not index_loaded:\n",
        "    print(\"  ❌ No index found. Please upload asme_visual_index.pkl:\")\n",
        "    from google.colab import files\n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "        for filename in uploaded:\n",
        "            if filename.endswith('.pkl'):\n",
        "                with open(filename, 'rb') as f:\n",
        "                    rag_data = pickle.load(f)\n",
        "                index_loaded = True\n",
        "                break\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "print(\"\\n[STEP 3/3] Looking for RAG Visual Database...\")\n",
        "\n",
        "# Check multiple locations for the image folder\n",
        "image_locations = [\n",
        "    \"/content/rag_visual_db\",\n",
        "    \"/content/rag_data/rag_visual_db\",\n",
        "    \"rag_visual_db\",\n",
        "]\n",
        "if 'DATA_DIR' in dir() and DATA_DIR:\n",
        "    image_locations.insert(0, os.path.join(DATA_DIR, \"rag_visual_db\"))\n",
        "\n",
        "found_images = False\n",
        "for loc in image_locations:\n",
        "    if loc and os.path.exists(loc) and os.path.isdir(loc):\n",
        "        # Count images\n",
        "        img_files = [f for f in os.listdir(loc) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        if len(img_files) > 0:\n",
        "            RAG_IMAGE_DIR = os.path.abspath(loc)\n",
        "            found_images = True\n",
        "            print(f\"  ✅ Found: {RAG_IMAGE_DIR} ({len(img_files)} images)\")\n",
        "            break\n",
        "\n",
        "if not found_images:\n",
        "    print(\"  ❌ No images found. Please upload rag_visual_db.zip:\")\n",
        "    from google.colab import files\n",
        "    import zipfile, shutil\n",
        "    try:\n",
        "        uploaded = files.upload()\n",
        "        for filename in uploaded:\n",
        "            if filename.lower().endswith('.zip'):\n",
        "                RAG_IMAGE_DIR = \"/content/rag_visual_db\"\n",
        "                if os.path.exists(RAG_IMAGE_DIR):\n",
        "                    shutil.rmtree(RAG_IMAGE_DIR)\n",
        "                os.makedirs(RAG_IMAGE_DIR, exist_ok=True)\n",
        "                with zipfile.ZipFile(filename, 'r') as zf:\n",
        "                    zf.extractall(RAG_IMAGE_DIR)\n",
        "                found_images = True\n",
        "                print(f\"  ✅ Extracted to {RAG_IMAGE_DIR}\")\n",
        "                break\n",
        "    except:\n",
        "        RAG_IMAGE_DIR = \"/content/rag_visual_db\"\n",
        "\n",
        "# Build search index\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "if index_loaded and len(rag_data) > 0:\n",
        "    embeddings_list = [item['embedding'] for item in rag_data]\n",
        "    rag_embeddings = np.array(embeddings_list).astype('float32')\n",
        "    rag_available = True\n",
        "    print(\"✅ RAG SYSTEM: READY\")\n",
        "    print(f\"  Index: {len(rag_data)} entries\")\n",
        "    print(f\"  Images: {RAG_IMAGE_DIR}\")\n",
        "else:\n",
        "    print(\"❌ RAG SYSTEM: NOT READY\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4A: Core Helper Functions\n",
        "# ============================================================\n",
        "import os\n",
        "import re\n",
        "from pdf2image import convert_from_path\n",
        "\n",
        "def extract_filename_key(filepath):\n",
        "    \"\"\"Extract filename key for lookup.\"\"\"\n",
        "    filename = os.path.basename(filepath)\n",
        "    name_no_ext = os.path.splitext(filename)[0]\n",
        "    name_no_ext = re.sub(r'\\s*\\(\\d+\\)$', '', name_no_ext)  # Remove (1), (2) etc\n",
        "    name_cleaned = re.sub(r'[\\s_]*(Paint|PAINT)$', '', name_no_ext, flags=re.IGNORECASE)\n",
        "    return name_cleaned.strip()\n",
        "\n",
        "def get_part_context(filepath):\n",
        "    \"\"\"Look up part context from filename.\"\"\"\n",
        "    filename_key = extract_filename_key(filepath)\n",
        "\n",
        "    if filename_key in filename_to_pn:\n",
        "        pn = filename_to_pn[filename_key]\n",
        "        lookup_key = normalize_pn(pn)\n",
        "        if lookup_key in part_context_db:\n",
        "            return pn, part_context_db[lookup_key]\n",
        "\n",
        "    for ext in ['.pdf', '.PDF']:\n",
        "        key = filename_key + ext\n",
        "        if key in filename_to_pn:\n",
        "            pn = filename_to_pn[key]\n",
        "            lookup_key = normalize_pn(pn)\n",
        "            if lookup_key in part_context_db:\n",
        "                return pn, part_context_db[lookup_key]\n",
        "\n",
        "    return None, None\n",
        "\n",
        "def build_context_string(pn, context):\n",
        "    \"\"\"Build the context string for inspection prompt.\"\"\"\n",
        "    if context is None:\n",
        "        return \"CONTEXT: Unknown Part (General Syntax Check Only).\"\n",
        "\n",
        "    desc = context.get('description', 'Unknown')\n",
        "    assembly = context.get('assembly', 'Unknown Assembly')\n",
        "    siblings = context.get('siblings', 'None listed')\n",
        "\n",
        "    return f\"\"\"CONTEXT: This is Part {pn} ({desc}).\n",
        "It belongs to the {assembly}.\n",
        "It must assemble with these mating parts: {siblings}.\n",
        "CRITICAL: Check for mating tolerances suitable for a {desc}.\"\"\"\n",
        "\n",
        "def pdf_to_image(pdf_path, dpi=150):\n",
        "    \"\"\"Convert first page of PDF to PIL Image.\"\"\"\n",
        "    pages = convert_from_path(pdf_path, dpi=dpi, first_page=1, last_page=1)\n",
        "    return pages[0] if pages else None\n",
        "\n",
        "print(\"✅ Core helper functions defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4B: Model Query Function\n",
        "# ============================================================\n",
        "import torch\n",
        "from qwen_vl_utils import process_vision_info\n",
        "\n",
        "def query_model(messages, max_tokens=1024):\n",
        "    \"\"\"Send a query to Qwen2-VL and get response.\"\"\"\n",
        "    if 'model' not in globals() or 'processor' not in globals():\n",
        "        raise RuntimeError(\"⚠️ Model not loaded. Run Cell 2 first.\")\n",
        "\n",
        "    text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    image_inputs, video_inputs = process_vision_info(messages)\n",
        "\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        videos=video_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output_ids = model.generate(**inputs, max_new_tokens=max_tokens, do_sample=False)\n",
        "\n",
        "    generated_ids = output_ids[:, inputs.input_ids.shape[1]:]\n",
        "    response = processor.batch_decode(generated_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n",
        "    return response.strip()\n",
        "\n",
        "print(\"✅ Model query function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4C: RAG Retrieval Function\n",
        "# ============================================================\n",
        "\n",
        "def retrieve_asme_pages(keywords, top_k=2):\n",
        "    \"\"\"Retrieve relevant ASME standard pages based on keywords.\"\"\"\n",
        "    global RAG_IMAGE_DIR\n",
        "\n",
        "    if not rag_available or rag_embeddings is None:\n",
        "        print(\"  ⚠️ RAG system not available\")\n",
        "        return []\n",
        "\n",
        "    if RAG_IMAGE_DIR is None:\n",
        "        print(\"  ⚠️ RAG_IMAGE_DIR not set\")\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        query_vector = search_model.encode([keywords])\n",
        "        scores = np.dot(query_vector, rag_embeddings.T).flatten()\n",
        "        top_indices = np.argsort(scores)[-top_k:][::-1]\n",
        "\n",
        "        retrieved_images = []\n",
        "        print(f\"  RAG Search: '{keywords[:50]}...'\")\n",
        "\n",
        "        for idx in top_indices:\n",
        "            item = rag_data[idx]\n",
        "            rel_path = item['path'].replace('\\\\', '/')\n",
        "\n",
        "            paths_to_try = [\n",
        "                os.path.join(RAG_IMAGE_DIR, rel_path),\n",
        "                os.path.join(RAG_IMAGE_DIR, os.path.basename(rel_path)),\n",
        "            ]\n",
        "\n",
        "            path_parts = rel_path.split('/')\n",
        "            if len(path_parts) > 1:\n",
        "                paths_to_try.append(os.path.join(RAG_IMAGE_DIR, path_parts[-1]))\n",
        "\n",
        "            print(f\"    - {os.path.basename(rel_path)} (Score: {scores[idx]:.3f})\")\n",
        "\n",
        "            for try_path in paths_to_try:\n",
        "                if os.path.exists(try_path):\n",
        "                    try:\n",
        "                        img = Image.open(try_path).convert('RGB')\n",
        "                        retrieved_images.append(img)\n",
        "                        break\n",
        "                    except Exception as e:\n",
        "                        print(f\"      Error: {e}\")\n",
        "\n",
        "        return retrieved_images\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"  RAG error: {e}\")\n",
        "        return []\n",
        "\n",
        "print(\"✅ RAG retrieval function defined.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 4D: Production Pipeline Helpers (Tesseract OCR + Tiling)\n",
        "# ============================================================\n",
        "import fitz  # PyMuPDF\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "import pytesseract\n",
        "\n",
        "print(\"⚙️ Initializing Production Pipeline...\")\n",
        "\n",
        "def render_pdf_page(pdf_path: str, dpi: int = 300) -> Image.Image:\n",
        "    \"\"\"Renders the first page of a PDF to a High-Res PIL Image using PyMuPDF.\"\"\"\n",
        "    try:\n",
        "        doc = fitz.open(pdf_path)\n",
        "        page = doc.load_page(0)\n",
        "        zoom = dpi / 72.0\n",
        "        mat = fitz.Matrix(zoom, zoom)\n",
        "        pix = page.get_pixmap(matrix=mat, alpha=False)\n",
        "        img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
        "        doc.close()\n",
        "        return img\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Rendering Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def run_tesseract_ocr(img: Image.Image) -> List[str]:\n",
        "    \"\"\"\n",
        "    Runs Tesseract OCR on the image and returns a sorted, unique list of text found.\n",
        "    Uses PSM 11 (Sparse Text) mode which is best for engineering drawings.\n",
        "    Normalizes common engineering symbols (Ø -> DIA).\n",
        "\n",
        "    Args:\n",
        "        img: PIL Image\n",
        "\n",
        "    Returns:\n",
        "        List of unique text strings found, sorted alphabetically\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Run Tesseract with sparse text mode (PSM 11)\n",
        "        raw_text = pytesseract.image_to_string(img, config='--psm 11')\n",
        "\n",
        "        # Split by newlines and clean\n",
        "        lines = raw_text.split('\\n')\n",
        "\n",
        "        texts = []\n",
        "        for line in lines:\n",
        "            # Strip whitespace\n",
        "            cleaned = line.strip()\n",
        "\n",
        "            # Skip empty lines\n",
        "            if not cleaned:\n",
        "                continue\n",
        "\n",
        "            # Skip garbage (less than 2 alphanumeric characters)\n",
        "            alphanumeric_count = sum(1 for c in cleaned if c.isalnum())\n",
        "            if alphanumeric_count < 2:\n",
        "                continue\n",
        "\n",
        "            # Normalize engineering symbols\n",
        "            cleaned = cleaned.replace(\"Ø\", \"DIA \")\n",
        "            cleaned = cleaned.replace(\"ø\", \"DIA \")\n",
        "\n",
        "            texts.append(cleaned)\n",
        "\n",
        "        # Deduplicate and sort\n",
        "        return sorted(list(set(texts)))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Tesseract OCR Error: {e}\")\n",
        "        return []\n",
        "\n",
        "def make_overlapping_tiles(full_img: Image.Image) -> List[Tuple[str, Image.Image]]:\n",
        "    \"\"\"Splits the image into 4 overlapping quadrants for better resolution.\"\"\"\n",
        "    w, h = full_img.size\n",
        "    tile_w, tile_h = w // 2, h // 2\n",
        "    overlap = int(min(w, h) * 0.15)\n",
        "\n",
        "    boxes = {\n",
        "        \"Top-Left\": (0, 0, tile_w + overlap, tile_h + overlap),\n",
        "        \"Top-Right\": (w - (tile_w + overlap), 0, w, tile_h + overlap),\n",
        "        \"Bottom-Left\": (0, h - (tile_h + overlap), tile_w + overlap, h),\n",
        "        \"Bottom-Right\": (w - (tile_w + overlap), h - (tile_h + overlap), w, h)\n",
        "    }\n",
        "\n",
        "    tiles = []\n",
        "    for name, box in boxes.items():\n",
        "        tiles.append((name, full_img.crop(box)))\n",
        "    return tiles\n",
        "\n",
        "print(\"✅ Production Pipeline Helpers Loaded (Tesseract OCR).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Main Inspection Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CELL 5B: UNIVERSAL MISMATCH INSPECTOR (Batch-Ready)\n",
        "# ============================================================\n",
        "\n",
        "def inspect_drawing_universal(pdf_path):\n",
        "    \"\"\"\n",
        "    Universal inspector that dynamically loads context for each file.\n",
        "    Batch-ready with robust error handling.\n",
        "    \"\"\"\n",
        "    # 1. Get Dynamic Context for THIS specific file\n",
        "    pn = None\n",
        "    try:\n",
        "        pn, ctx = get_part_context(pdf_path)\n",
        "        context_str = ctx['siblings']  # Fixed: was 'siblings_str'\n",
        "        part_name = ctx['description']  # Fixed: was 'desc'\n",
        "    except:\n",
        "        print(f\"⚠️ Context Lookup Failed for {pdf_path}\")\n",
        "        context_str = \"No Mating Parts Found in Database.\"\n",
        "        part_name = \"Unknown Part\"\n",
        "\n",
        "    print(f\"\\n{'='*60}\\nUNIVERSAL INSPECTION: {part_name}\\n{'='*60}\")\n",
        "\n",
        "    # --- Phase A: Perception ---\n",
        "    print(\"[1/3] Reading Drawing (Tesseract OCR)...\")\n",
        "    full_img = render_pdf_page(pdf_path, dpi=300)\n",
        "    if not full_img:\n",
        "        return {'error': 'Failed to render PDF', 'part_number': pn}\n",
        "\n",
        "    # Run Tesseract\n",
        "    ocr_texts = run_tesseract_ocr(full_img)\n",
        "    # Filter for relevant engineering text (numbers/dims)\n",
        "    filtered_ocr = [t for t in ocr_texts if any(char.isdigit() for char in t)]\n",
        "    ocr_block = \"\\n\".join([f\"- {t}\" for t in filtered_ocr[:120]])\n",
        "\n",
        "    print(f\"  > Evidence: {len(filtered_ocr)} relevant lines found.\")\n",
        "\n",
        "    # --- Phase B: Reasoning ---\n",
        "    print(\"[2/3] Generating Dynamic Truth Table...\")\n",
        "\n",
        "    system_prompt = \"\"\"You are a Universal Engineering Auditor.\n",
        "\n",
        "**YOUR GOAL:**\n",
        "Cross-reference \"LIST A\" (Requirements) against \"LIST B\" (Drawing Evidence).\n",
        "\n",
        "**LOGIC PROTOCOL:**\n",
        "1. Read LIST A to identify the Mating Parts.\n",
        "2. For EACH Mating Part, search LIST B for a corresponding feature (Thread, Hole, Diameter).\n",
        "3. **STRICTLY** compare dimensions.\n",
        "   - If List A says \"3/4-16\" and List B says \"M10\", output NO.\n",
        "   - If List A says \"0.750\" and List B says \"0.500\", output NO.\n",
        "4. If the Mating Part is generic (e.g. \"WASHER\"), and you see *any* washer dimension, you may output \"LIKELY MATCH\".\n",
        "5. If you cannot find any matching text in List B, output \"NOT FOUND\".\"\"\"\n",
        "\n",
        "    user_text = f\"\"\"**LIST A (THE REQUIREMENTS for Part {pn}):**\n",
        "{context_str}\n",
        "\n",
        "**LIST B (THE DRAWING TEXT):**\n",
        "{ocr_block}\n",
        "\n",
        "**TASK:**\n",
        "Create a Truth Table checking the compatibility of the Mating Parts in List A against the Evidence in List B.\n",
        "\n",
        "| Mating Part (from List A) | Found Feature in List B | Compatible? (YES/NO/NOT FOUND) |\n",
        "| :--- | :--- | :--- |\n",
        "| [Name/Spec of Part 1] | [Text from Drawing] | [Verdict] |\n",
        "| [Name/Spec of Part 2] | [Text from Drawing] | [Verdict] |\n",
        "\n",
        "**FINAL VERDICT:**\n",
        "PASS if all critical features match.\n",
        "FAIL if there is a direct contradiction (Metric vs Imperial).\"\"\"\n",
        "\n",
        "    content_payload = [\n",
        "        {'type': 'image', 'image': full_img},\n",
        "        {'type': 'text', 'text': user_text}\n",
        "    ]\n",
        "\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': system_prompt},\n",
        "        {'role': 'user', 'content': content_payload}\n",
        "    ]\n",
        "\n",
        "    # Inference\n",
        "    print(\"[3/3] Running inference...\")\n",
        "    text_input = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = processor(\n",
        "        text=[text_input],\n",
        "        images=[full_img],\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True\n",
        "    ).to(model.device)\n",
        "\n",
        "    token_count = inputs.input_ids.shape[1]\n",
        "    print(f\"  Token count: {token_count}\")\n",
        "\n",
        "    generated_ids = model.generate(**inputs, max_new_tokens=600)\n",
        "    output_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "\n",
        "    response = output_text.split(\"assistant\\n\")[-1] if \"assistant\\n\" in output_text else output_text\n",
        "\n",
        "    print(f\"\\n{'='*60}\\nRESULT:\\n{'='*60}\")\n",
        "    print(response)\n",
        "\n",
        "    return {\n",
        "        'response': response,\n",
        "        'part_number': pn,\n",
        "        'part_name': part_name,\n",
        "        'ocr_total': len(ocr_texts),\n",
        "        'ocr_filtered': len(filtered_ocr),\n",
        "        'token_count': token_count\n",
        "    }\n",
        "\n",
        "# Aliases for compatibility\n",
        "inspect_drawing_strict_optimized = inspect_drawing_universal\n",
        "inspect_drawing_production = inspect_drawing_universal\n",
        "\n",
        "print(\"✅ Universal Inspector Loaded (Batch-Ready).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": "# ============================================================\n# CELL 5D: MASTER PIPELINE - Full Inspection (Stage 1 + Stage 2)\n# ============================================================\nfrom datetime import datetime\nimport re\n\ndef parse_verdict(response_text):\n    \"\"\"\n    Parse the truth table response to determine PASS/FAIL.\n    Returns FAIL if any row has 'NO', PASS if all rows have 'YES'.\n    \"\"\"\n    if not response_text:\n        return 'ERROR', 'No response'\n\n    text_upper = response_text.upper()\n\n    # Count YES and NO in the response\n    yes_count = len(re.findall(r'\\|\\s*YES\\s*\\|', text_upper))\n    no_count = len(re.findall(r'\\|\\s*NO\\s*\\|', text_upper))\n\n    # Also check for standalone YES/NO at end of lines\n    yes_count += len(re.findall(r'YES\\s*$', text_upper, re.MULTILINE))\n    no_count += len(re.findall(r'NO\\s*$', text_upper, re.MULTILINE))\n\n    # Check for NOT FOUND\n    not_found = 'NOT FOUND' in text_upper\n\n    # Determine verdict\n    if no_count > 0 or not_found:\n        issues = []\n        if no_count > 0:\n            issues.append(f\"{no_count} mismatches\")\n        if not_found:\n            issues.append(\"missing specs\")\n        return 'FAIL', '; '.join(issues)\n    elif yes_count > 0:\n        return 'PASS', f\"{yes_count} specs verified\"\n    else:\n        return 'REVIEW', 'Could not parse verdict'\n\n\ndef run_full_inspection(pdf_path, skip_stage2_on_fail=True):\n    \"\"\"\n    Master pipeline that runs both inspection stages:\n\n    Stage 1 (Gatekeeper): Strict mismatch detection\n    Stage 2 (Consultant): Improvement suggestions (only if Stage 1 passes)\n    \"\"\"\n    print(f\"\\n{'#'*60}\")\n    print(f\"# FULL ENGINEERING INSPECTION PIPELINE\")\n    print(f\"# File: {os.path.basename(pdf_path)}\")\n    print(f\"# Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n    print(f\"{'#'*60}\")\n\n    result = {\n        'file': os.path.basename(pdf_path),\n        'path': pdf_path,\n        'timestamp': datetime.now().isoformat(),\n        'stage1': None,\n        'stage2': None,\n        'final_verdict': None\n    }\n\n    # STAGE 1: THE GATEKEEPER\n    print(f\"\\n{'='*60}\")\n    print(\"STAGE 1: THE GATEKEEPER (Mismatch Detection)\")\n    print(f\"{'='*60}\")\n\n    pn, ctx = get_part_context(pdf_path)\n\n    if not ctx:\n        print(f\"⚠️ No context found for {pdf_path}\")\n        result['stage1'] = {'verdict': 'ERROR', 'reason': 'Part not in database'}\n        result['final_verdict'] = 'ERROR'\n        return result\n\n    context_data = {\n        'pn': pn,\n        'description': ctx.get('description', 'Unknown'),\n        'assembly': ctx.get('assembly', 'Unknown'),\n        'siblings': ctx.get('siblings', 'No mating parts')\n    }\n\n    stage1_result = inspect_drawing_universal(pdf_path)\n\n    if isinstance(stage1_result, dict) and 'error' in stage1_result:\n        stage1_verdict = 'ERROR'\n        stage1_reason = stage1_result['error']\n        response = ''\n    else:\n        response = stage1_result.get('response', '') if isinstance(stage1_result, dict) else str(stage1_result)\n        stage1_verdict, stage1_reason = parse_verdict(response)\n\n    result['stage1'] = {\n        'verdict': stage1_verdict,\n        'reason': stage1_reason,\n        'part_number': pn,\n        'part_name': context_data['description'],\n        'ocr_count': stage1_result.get('ocr_filtered', 0) if isinstance(stage1_result, dict) else 0,\n        'response': response[:1000]\n    }\n\n    print(f\"\\n>>> STAGE 1 VERDICT: {stage1_verdict} - {stage1_reason}\")\n\n    # STAGE 2: THE CONSULTANT\n    if stage1_verdict == 'FAIL' and skip_stage2_on_fail:\n        print(f\"\\n{'='*60}\")\n        print(\"STAGE 2: SKIPPED (Stage 1 Failed)\")\n        print(f\"{'='*60}\")\n        print(\"Fix the Stage 1 issues before requesting improvement suggestions.\")\n        result['stage2'] = {'status': 'SKIPPED', 'reason': 'Stage 1 failed'}\n        result['final_verdict'] = 'FAIL'\n\n    elif stage1_verdict == 'ERROR':\n        print(f\"\\n{'='*60}\")\n        print(\"STAGE 2: SKIPPED (Stage 1 Error)\")\n        print(f\"{'='*60}\")\n        result['stage2'] = {'status': 'SKIPPED', 'reason': 'Stage 1 error'}\n        result['final_verdict'] = 'ERROR'\n\n    else:\n        print(f\"\\n{'='*60}\")\n        print(\"STAGE 2: THE CONSULTANT (Proceeding...)\")\n        print(f\"{'='*60}\")\n\n        ocr_text_list = []\n        if isinstance(stage1_result, dict):\n            full_img = render_pdf_page(pdf_path, dpi=200)\n            if full_img:\n                ocr_text_list = run_tesseract_ocr(full_img)\n                ocr_text_list = [t for t in ocr_text_list if any(c.isdigit() for c in t)]\n\n        try:\n            stage2_result = suggest_improvements_stage2(\n                pdf_path=pdf_path,\n                context_data=context_data,\n                ocr_text_list=ocr_text_list\n            )\n\n            result['stage2'] = {\n                'status': 'COMPLETED',\n                'suggestions': stage2_result.get('suggestions', ''),\n                'asme_pages_used': stage2_result.get('asme_pages_used', 0),\n                'search_queries': stage2_result.get('search_queries', [])\n            }\n\n        except Exception as e:\n            print(f\"⚠️ Stage 2 Error: {e}\")\n            result['stage2'] = {'status': 'ERROR', 'reason': str(e)}\n\n        result['final_verdict'] = 'PASS_WITH_SUGGESTIONS' if stage1_verdict == 'PASS' else 'REVIEW'\n\n    # FINAL SUMMARY\n    print(f\"\\n{'#'*60}\")\n    print(\"# FINAL INSPECTION SUMMARY\")\n    print(f\"{'#'*60}\")\n    print(f\"Part: {pn} ({context_data['description']})\")\n    print(f\"Stage 1 (Gatekeeper): {result['stage1']['verdict']}\")\n    print(f\"Stage 2 (Consultant): {result['stage2'].get('status', 'N/A')}\")\n    print(f\"Final Verdict: {result['final_verdict']}\")\n    print(f\"{'#'*60}\\n\")\n\n    return result\n\n\ndef run_full_inspection_batch(drawing_folder, output_file=None, limit=None):\n    \"\"\"Run full inspection on all PDFs in a folder.\"\"\"\n    from tqdm.notebook import tqdm\n\n    pdf_files = glob.glob(os.path.join(drawing_folder, \"**/*.pdf\"), recursive=True)\n    pdf_files += glob.glob(os.path.join(drawing_folder, \"**/*.PDF\"), recursive=True)\n    pdf_files = sorted(list(set(pdf_files)))\n\n    if limit:\n        pdf_files = pdf_files[:limit]\n\n    print(f\"{'#'*60}\")\n    print(f\"FULL INSPECTION BATCH: {len(pdf_files)} files\")\n    print(f\"{'#'*60}\\n\")\n\n    results = []\n\n    for pdf_path in tqdm(pdf_files, desc=\"Full Inspection\"):\n        try:\n            result = run_full_inspection(pdf_path)\n            results.append(result)\n        except Exception as e:\n            results.append({'file': os.path.basename(pdf_path), 'final_verdict': 'ERROR', 'error': str(e)})\n\n    if not output_file:\n        output_file = f\"full_inspection_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n\n    with open(output_file, 'w') as f:\n        json.dump(results, f, indent=2)\n\n    verdicts = [r.get('final_verdict', 'ERROR') for r in results]\n    print(f\"\\n{'='*60}\")\n    print(f\"BATCH SUMMARY: {len(results)} files\")\n    print(f\"PASS: {verdicts.count('PASS_WITH_SUGGESTIONS')} | FAIL: {verdicts.count('FAIL')} | ERROR: {verdicts.count('ERROR')}\")\n    print(f\"Results: {output_file}\")\n\n    return results\n\nprint(\"✅ parse_verdict() defined.\")\nprint(\"✅ run_full_inspection() defined.\")\nprint(\"✅ run_full_inspection_batch() defined.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Inspect a Drawing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload and inspect a single PDF drawing\nfrom google.colab import files\n\nprint(\"Upload a PDF drawing to inspect:\")\nuploaded = files.upload()\n\nif uploaded:\n    pdf_path = list(uploaded.keys())[0]\n    print(f\"\nInspecting: {pdf_path}\")\n    result = run_full_inspection(pdf_path)\n    \n    # Display result summary\n    print(\"\n\" + \"=\"*60)\n    print(\"INSPECTION COMPLETE\")\n    print(\"=\"*60)\n    if 'verdict' in result:\n        print(f\"Verdict: {result['verdict']}\")\n    if 'reason' in result:\n        print(f\"Reason: {result['reason']}\")\nelse:\n    print(\"No file uploaded.\")\n"
      ]
    }
  ]
}