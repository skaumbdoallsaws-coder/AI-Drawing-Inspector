{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/skaumbdoallsaws-coder/AI-Drawing-Inspector/blob/main/ai_inspector_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0QxQqDl17wtB"
   },
   "source": [
    "# AI Engineering Drawing Inspector v3.0\n\n**Multi-Model QC Pipeline**\n\nOutputs:\n1. `ResolvedPartIdentity.json`\n2. `QwenUnderstanding.json` (features, quality, BOM, mfg notes)\n3. `DrawingEvidence.json`\n4. `DiffResult.json`\n5. `QCReport.md`\n\n**v3.0 Enhancements (Planned):**\n- Batch processing mode\n- Low feature count warnings\n- Improved deduplication\n- GD&T symbol detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kUxTZFYm7wtC",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f828d6b8-8e55-40f6-f2a8-e199d7911be1"
   },
   "outputs": [],
   "source": "# Cell 1: Install Dependencies\n!pip install -q pymupdf opencv-python-headless jsonschema pillow pytesseract\n!pip install -q accelerate qwen-vl-utils bitsandbytes\n!pip install -q git+https://github.com/huggingface/transformers\n!pip install -q json-repair openai\n!apt-get install -y poppler-utils tesseract-ocr > /dev/null 2>&1\nprint(\"Dependencies installed!\")"
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 2: Imports and Configuration\n",
    "import os, json, re, gc\n",
    "import torch\n",
    "import fitz\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from typing import List, Dict, Any, Optional, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "# Configuration\n",
    "DRAWING_PDF_PATH = \"\"\n",
    "SOLIDWORKS_JSON_DIR = \"sw_json_library\"\n",
    "OUTPUT_DIR = \"qc_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA: {torch.cuda.is_available()}\")"
   ],
   "metadata": {
    "id": "BywKsGSW7wtD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "71bdd93a-ff42-4206-b2a9-2e66aeed8ac8"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 3: BOM-Robust JSON Loader\n",
    "def load_json_robust(filepath) -> Tuple[Optional[Dict], Optional[str]]:\n",
    "    \"\"\"Load JSON with BOM handling. Tries: utf-8-sig, utf-8, latin-1\"\"\"\n",
    "    filepath = Path(filepath)\n",
    "    for enc in ['utf-8-sig', 'utf-8', 'latin-1']:\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding=enc) as f:\n",
    "                return json.load(f), None\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "        except json.JSONDecodeError as e:\n",
    "            if 'BOM' in str(e) and enc == 'utf-8':\n",
    "                continue\n",
    "            return None, f\"JSON error: {str(e)[:50]}\"\n",
    "        except Exception as e:\n",
    "            return None, f\"Error: {str(e)[:50]}\"\n",
    "    return None, \"Failed all encodings\"\n",
    "\n",
    "print(\"load_json_robust defined\")"
   ],
   "metadata": {
    "id": "Fip3em4Z7wtD",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "01b8d138-42d3-4863-89c5-8f488930e250"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 4: PDF Rendering\n",
    "@dataclass\n",
    "class PageArtifact:\n",
    "    pageIndex0: int\n",
    "    page: int\n",
    "    image: Image.Image\n",
    "    width: int\n",
    "    height: int\n",
    "    dpi: int\n",
    "    direct_text: Optional[str] = None\n",
    "\n",
    "def render_pdf(pdf_path: str, dpi: int = 300) -> List[PageArtifact]:\n",
    "    \"\"\"Render first page of PDF to image.\"\"\"\n",
    "    artifacts = []\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(0)\n",
    "    zoom = dpi / 72.0\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(zoom, zoom), alpha=False)\n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    direct_text = page.get_text(\"text\")\n",
    "\n",
    "    artifacts.append(PageArtifact(\n",
    "        pageIndex0=0, page=1, image=img,\n",
    "        width=pix.width, height=pix.height, dpi=dpi,\n",
    "        direct_text=direct_text if len(direct_text.strip()) > 10 else None\n",
    "    ))\n",
    "    doc.close()\n",
    "    print(f\"Rendered: {pix.width}x{pix.height}px\")\n",
    "    return artifacts\n",
    "\n",
    "print(\"render_pdf defined\")"
   ],
   "metadata": {
    "id": "g5CgMeOp7wtD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 5: SolidWorks JSON Library\n",
    "@dataclass\n",
    "class SwPartEntry:\n",
    "    json_path: str\n",
    "    part_number: str\n",
    "    filename_stem: str = \"\"\n",
    "    data: Dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "class SwJsonLibrary:\n",
    "    def __init__(self):\n",
    "        self.by_part_number: Dict[str, SwPartEntry] = {}\n",
    "        self.by_filename: Dict[str, SwPartEntry] = {}\n",
    "        self.all_entries: List[SwPartEntry] = []\n",
    "\n",
    "    def _normalize(self, s: str) -> str:\n",
    "        return re.sub(r'[-\\s_]', '', str(s or '')).lower()\n",
    "\n",
    "    def load_from_directory(self, directory: str):\n",
    "        json_files = list(Path(directory).glob(\"**/*.json\"))\n",
    "        print(f\"Found {len(json_files)} JSON files\")\n",
    "\n",
    "        for jp in json_files:\n",
    "            data, err = load_json_robust(jp)\n",
    "            if data is None:\n",
    "                continue\n",
    "            pn = data.get('identity', {}).get('partNumber', '')\n",
    "            entry = SwPartEntry(str(jp), pn, jp.stem, data)\n",
    "            self.all_entries.append(entry)\n",
    "            if pn:\n",
    "                self.by_part_number[pn] = entry\n",
    "                self.by_part_number[self._normalize(pn)] = entry\n",
    "            self.by_filename[jp.stem] = entry\n",
    "            self.by_filename[self._normalize(jp.stem)] = entry\n",
    "        print(f\"Loaded {len(self.all_entries)} files\")\n",
    "\n",
    "    def lookup(self, candidate: str) -> Optional[SwPartEntry]:\n",
    "        if not candidate:\n",
    "            return None\n",
    "        norm = self._normalize(candidate)\n",
    "        return self.by_part_number.get(candidate) or self.by_part_number.get(norm) or \\\n",
    "               self.by_filename.get(candidate) or self.by_filename.get(norm)\n",
    "\n",
    "sw_library = SwJsonLibrary()\n",
    "print(\"SwJsonLibrary defined\")"
   ],
   "metadata": {
    "id": "w7qDW6w27wtE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 6: Part Identity Resolution (Robust Matching)\n",
    "\n",
    "@dataclass\n",
    "class ResolvedPartIdentity:\n",
    "    partNumber: str\n",
    "    confidence: float\n",
    "    source: str\n",
    "    swJsonPath: Optional[str] = None\n",
    "    candidates_tried: List[str] = field(default_factory=list)\n",
    "\n",
    "def clean_filename(filename: str) -> str:\n",
    "    \"\"\"Remove known suffixes like Paint, REV, etc.\"\"\"\n",
    "    cleaned = re.sub(r'[\\s_]*(Paint|PAINT)$', '', filename, flags=re.IGNORECASE)\n",
    "    return cleaned.strip()\n",
    "\n",
    "def extract_pn_candidates(filename: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract potential part number candidates from filename.\n",
    "    Handles: 1013572_01, 101357201-03, 314884W_0, 046-935-REV-A\n",
    "    Returns list of candidates (most specific to least).\n",
    "    \"\"\"\n",
    "    name_no_ext = os.path.splitext(filename)[0]\n",
    "    # Remove duplicate markers like (1), (2)\n",
    "    name_no_ext = re.sub(r'\\s*\\(\\d+\\)$', '', name_no_ext)\n",
    "    cleaned = clean_filename(name_no_ext)\n",
    "    parts = re.split(r'[\\s_]+', cleaned)\n",
    "\n",
    "    if not parts:\n",
    "        return []\n",
    "\n",
    "    base = parts[0]\n",
    "    candidates = []\n",
    "\n",
    "    # 1. Base as-is\n",
    "    candidates.append(base)\n",
    "\n",
    "    # 2. Without hyphens\n",
    "    base_no_hyphen = base.replace('-', '')\n",
    "    if base_no_hyphen != base:\n",
    "        candidates.append(base_no_hyphen)\n",
    "\n",
    "    # 3. Remove letter suffixes (046-935A -> 046-935)\n",
    "    if base and base[-1].isalpha() and len(base) > 1:\n",
    "        candidates.append(base[:-1])\n",
    "        candidates.append(base[:-1].replace('-', ''))\n",
    "\n",
    "    # 4. Handle revision pattern (046-935-01 -> 046-935)\n",
    "    rev_match = re.match(r'^(.+)-(\\d{1,2})$', base)\n",
    "    if rev_match:\n",
    "        main_part = rev_match.group(1)\n",
    "        candidates.append(main_part)\n",
    "        candidates.append(main_part.replace('-', ''))\n",
    "\n",
    "    # 5. Handle REV suffix (046-935-REV-A -> 046-935)\n",
    "    rev_alpha = re.match(r'^(.+?)[-_]?REV[-_]?[A-Z0-9]*$', base, re.IGNORECASE)\n",
    "    if rev_alpha:\n",
    "        candidates.append(rev_alpha.group(1))\n",
    "        candidates.append(rev_alpha.group(1).replace('-', ''))\n",
    "\n",
    "    # 6. Peeling - progressively remove trailing digits\n",
    "    temp = base_no_hyphen\n",
    "    while len(temp) > 5:\n",
    "        temp = temp[:-1]\n",
    "        candidates.append(temp)\n",
    "\n",
    "    # Remove duplicates, preserve order\n",
    "    seen = set()\n",
    "    unique = []\n",
    "    for c in candidates:\n",
    "        if c and c not in seen:\n",
    "            seen.add(c)\n",
    "            unique.append(c)\n",
    "\n",
    "    return unique\n",
    "\n",
    "def resolve_part_identity(pdf_path: str, artifacts: List[PageArtifact], sw_lib: SwJsonLibrary) -> ResolvedPartIdentity:\n",
    "    \"\"\"Resolve part identity using robust filename matching.\"\"\"\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    candidates = extract_pn_candidates(filename)\n",
    "\n",
    "    # Try each candidate against SW library\n",
    "    for candidate in candidates:\n",
    "        entry = sw_lib.lookup(candidate)\n",
    "        if entry:\n",
    "            return ResolvedPartIdentity(\n",
    "                partNumber=entry.part_number or candidate,\n",
    "                confidence=1.0,\n",
    "                source=\"filename+sw\",\n",
    "                swJsonPath=entry.json_path,\n",
    "                candidates_tried=candidates\n",
    "            )\n",
    "\n",
    "    # Try PDF embedded text\n",
    "    for art in artifacts:\n",
    "        if art.direct_text:\n",
    "            text_candidates = extract_pn_candidates(art.direct_text[:200])\n",
    "            for candidate in text_candidates[:5]:\n",
    "                entry = sw_lib.lookup(candidate)\n",
    "                if entry:\n",
    "                    return ResolvedPartIdentity(\n",
    "                        partNumber=entry.part_number or candidate,\n",
    "                        confidence=0.8,\n",
    "                        source=\"pdf_text+sw\",\n",
    "                        swJsonPath=entry.json_path,\n",
    "                        candidates_tried=candidates + text_candidates[:5]\n",
    "                    )\n",
    "\n",
    "    # Fallback - use first candidate or filename stem\n",
    "    fallback_pn = candidates[0] if candidates else Path(pdf_path).stem\n",
    "    return ResolvedPartIdentity(\n",
    "        partNumber=fallback_pn,\n",
    "        confidence=0.3,\n",
    "        source=\"fallback\",\n",
    "        swJsonPath=None,\n",
    "        candidates_tried=candidates\n",
    "    )\n",
    "\n",
    "print(\"resolve_part_identity defined (robust matching)\")"
   ],
   "metadata": {
    "id": "U5TWtUzhJnRw"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 7: Load SolidWorks Library (Upload ZIP)\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "if not os.path.exists(SOLIDWORKS_JSON_DIR) or not list(Path(SOLIDWORKS_JSON_DIR).glob(\"*.json\")):\n",
    "    print(\"Upload your sw_json_library.zip file:\")\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    for filename in uploaded:\n",
    "        if filename.endswith('.zip'):\n",
    "            print(f\"Extracting {filename}...\")\n",
    "            with zipfile.ZipFile(filename, 'r') as z:\n",
    "                z.extractall(SOLIDWORKS_JSON_DIR)\n",
    "            print(f\"Extracted to {SOLIDWORKS_JSON_DIR}\")\n",
    "            break\n",
    "\n",
    "sw_library.load_from_directory(SOLIDWORKS_JSON_DIR)\n",
    "print(f\"Library ready: {len(sw_library.all_entries)} parts indexed\")"
   ],
   "metadata": {
    "id": "qOgdhn3iJnRx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 8: Upload and Render PDF Drawing\n",
    "from google.colab import files\n",
    "from IPython.display import display\n",
    "\n",
    "print(\"Upload your PDF drawing:\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename in uploaded:\n",
    "    if filename.lower().endswith('.pdf'):\n",
    "        DRAWING_PDF_PATH = filename\n",
    "        break\n",
    "\n",
    "print(f\"Processing: {DRAWING_PDF_PATH}\")\n",
    "artifacts = render_pdf(DRAWING_PDF_PATH)\n",
    "\n",
    "# Display the rendered image\n",
    "if artifacts:\n",
    "    display(artifacts[0].image.resize((800, int(800 * artifacts[0].height / artifacts[0].width))))"
   ],
   "metadata": {
    "id": "ZQJrQtNzJnRx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 9: Resolve Part Identity\n",
    "part_identity = resolve_part_identity(DRAWING_PDF_PATH, artifacts, sw_library)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"RESOLVED PART IDENTITY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Part Number:  {part_identity.partNumber}\")\n",
    "print(f\"Confidence:   {part_identity.confidence}\")\n",
    "print(f\"Source:       {part_identity.source}\")\n",
    "print(f\"SW JSON:      {part_identity.swJsonPath or 'Not found'}\")\n",
    "print(f\"Candidates:   {part_identity.candidates_tried[:5]}\")\n",
    "\n",
    "# Save to output\n",
    "identity_out = os.path.join(OUTPUT_DIR, \"ResolvedPartIdentity.json\")\n",
    "with open(identity_out, 'w') as f:\n",
    "    json.dump(asdict(part_identity), f, indent=2)\n",
    "print(f\"\\nSaved: {identity_out}\")"
   ],
   "metadata": {
    "id": "nWyBd12_JnRx"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Cell 10: Load LightOnOCR-2 and Run OCR\n",
    "from transformers import LightOnOcrForConditionalGeneration, LightOnOcrProcessor\n",
    "from google.colab import userdata\n",
    "\n",
    "# Clear GPU memory\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Get HF token\n",
    "try:\n",
    "    hf_token = userdata.get('HF_TOKEN')\n",
    "except:\n",
    "    hf_token = None\n",
    "\n",
    "print(\"Loading LightOnOCR-2-1B...\")\n",
    "ocr_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "ocr_dtype = torch.bfloat16 if ocr_device == \"cuda\" else torch.float32\n",
    "\n",
    "ocr_processor = LightOnOcrProcessor.from_pretrained(\n",
    "    \"lightonai/LightOnOCR-2-1B\",\n",
    "    token=hf_token\n",
    ")\n",
    "\n",
    "ocr_model = LightOnOcrForConditionalGeneration.from_pretrained(\n",
    "    \"lightonai/LightOnOCR-2-1B\",\n",
    "    torch_dtype=ocr_dtype,\n",
    "    token=hf_token\n",
    ").to(ocr_device)\n",
    "\n",
    "print(f\"LightOnOCR-2 loaded: {ocr_model.get_memory_footprint() / 1e9:.2f} GB\")\n",
    "\n",
    "def run_lighton_ocr(image: Image.Image) -> List[str]:\n",
    "    \"\"\"Run LightOnOCR-2 on image, return list of text lines.\"\"\"\n",
    "    global ocr_model, ocr_processor, ocr_device, ocr_dtype\n",
    "\n",
    "    img = image.convert(\"RGB\")\n",
    "    conversation = [{\"role\": \"user\", \"content\": [{\"type\": \"image\", \"image\": img}]}]\n",
    "\n",
    "    inputs = ocr_processor.apply_chat_template(\n",
    "        conversation, add_generation_prompt=True, tokenize=True,\n",
    "        return_dict=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs = {k: v.to(device=ocr_device, dtype=ocr_dtype) if v.is_floating_point() else v.to(ocr_device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output_ids = ocr_model.generate(**inputs, max_new_tokens=2048)\n",
    "\n",
    "    generated_ids = output_ids[0, inputs[\"input_ids\"].shape[1]:]\n",
    "    output_text = ocr_processor.decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    return [line.strip() for line in output_text.split(\"\\n\") if line.strip()]\n",
    "\n",
    "# Run OCR on the drawing\n",
    "print(\"Running OCR on drawing...\")\n",
    "ocr_lines = run_lighton_ocr(artifacts[0].image)\n",
    "print(f\"OCR extracted {len(ocr_lines)} lines\")\n",
    "print(\"\\nFirst 10 lines:\")\n",
    "for line in ocr_lines[:10]:\n",
    "    print(f\"  {line}\")"
   ],
   "metadata": {
    "id": "NQuVga-jJnRx",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "6d8cb633637947beb0986365e507fb89",
      "11d6a066a09f4ab6985c9cebdc01f28c",
      "20d47e35df1b4654a1caccd298981e41",
      "4feae93817e14b79b7315bdd01fc7694",
      "ee59d6c245604de5810ca56238df624d",
      "395213106c784b698b3227e0b8411eba",
      "76a15fdc82ad45c2bd70db4305a4ead8",
      "c4e75a9efb19494c9f585ee543060497",
      "af8de84578af4d04825ca6397a1b5457",
      "17c59dd010d74fbfa92ffdbb4e926348",
      "36cb6ddc8dac4afcae53de9d93378244"
     ]
    },
    "outputId": "35dc45ce-b8d0-4101-80a5-0fcbfbf56a70"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 10b: Qwen2.5-VL Drawing Understanding + Quality Audit + BOM + Mfg Notes\nfrom transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\nfrom qwen_vl_utils import process_vision_info\nfrom json_repair import repair_json\n\n# Clear some GPU memory before loading Qwen\ngc.collect()\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n\nprint(\"Loading Qwen2.5-VL-7B for drawing understanding...\")\nqwen_model_id = \"Qwen/Qwen2.5-VL-7B-Instruct\"\n\nqwen_processor = AutoProcessor.from_pretrained(qwen_model_id, trust_remote_code=True)\nqwen_model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n    qwen_model_id,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n    trust_remote_code=True\n)\nprint(f\"Qwen2.5-VL loaded: {qwen_model.get_memory_footprint() / 1e9:.2f} GB\")\n\ndef run_qwen_analysis(image: Image.Image, prompt: str) -> Dict[str, Any]:\n    \"\"\"Run Qwen2.5-VL with a given prompt and return parsed JSON.\"\"\"\n    messages = [\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"image\", \"image\": image},\n                {\"type\": \"text\", \"text\": prompt}\n            ]\n        }\n    ]\n\n    text = qwen_processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    image_inputs, video_inputs = process_vision_info(messages)\n\n    inputs = qwen_processor(\n        text=[text],\n        images=image_inputs,\n        videos=video_inputs,\n        padding=True,\n        return_tensors=\"pt\"\n    ).to(qwen_model.device)\n\n    with torch.no_grad():\n        output_ids = qwen_model.generate(**inputs, max_new_tokens=4096, temperature=0.1)\n\n    generated_ids = output_ids[0, inputs.input_ids.shape[1]:]\n    response = qwen_processor.decode(generated_ids, skip_special_tokens=True)\n\n    # Parse JSON from response with repair\n    try:\n        json_match = re.search(r'```json\\s*([\\s\\S]*?)\\s*```', response)\n        if json_match:\n            json_str = json_match.group(1)\n        else:\n            json_match = re.search(r'\\{[\\s\\S]*\\}', response)\n            json_str = json_match.group() if json_match else response\n\n        try:\n            return json.loads(json_str)\n        except json.JSONDecodeError:\n            print(\"  Attempting JSON repair...\")\n            repaired = repair_json(json_str)\n            return json.loads(repaired)\n\n    except Exception as e:\n        return {\"raw_response\": response[:1000], \"parse_error\": str(e)}\n\n# === ANALYSIS 1: Feature Extraction ===\nfeature_prompt = \"\"\"Analyze this engineering drawing and identify all features. Return a JSON object with:\n\n{\n  \"partDescription\": \"brief description of the part\",\n  \"views\": [\"list of views shown: TOP, FRONT, SIDE, ISOMETRIC, SECTION, DETAIL\"],\n  \"features\": [\n    {\n      \"type\": \"TappedHole|ThroughHole|BlindHole|Counterbore|Countersink|Slot|Fillet|Chamfer|Thread\",\n      \"description\": \"brief description\",\n      \"callout\": \"the dimension/callout text if visible\",\n      \"quantity\": 1,\n      \"location\": \"where on the part\"\n    }\n  ],\n  \"material\": \"material if shown in title block\",\n  \"titleBlockInfo\": {\n    \"partNumber\": \"if visible\",\n    \"revision\": \"if visible\",\n    \"scale\": \"if visible\"\n  },\n  \"notes\": [\"any general notes visible on drawing\"]\n}\n\nBe thorough - identify ALL holes, threads, chamfers, fillets, and other machined features you can see.\nOnly return valid JSON, no other text.\"\"\"\n\nprint(\"Analyzing drawing features with Qwen2.5-VL...\")\nqwen_understanding = run_qwen_analysis(artifacts[0].image, feature_prompt)\n\nprint(\"=\"*50)\nprint(\"QWEN2.5-VL FEATURE ANALYSIS\")\nprint(\"=\"*50)\n\nif \"parse_error\" not in qwen_understanding:\n    print(f\"Part: {qwen_understanding.get('partDescription', 'N/A')}\")\n    print(f\"Views: {qwen_understanding.get('views', [])}\")\n    print(f\"Material: {qwen_understanding.get('material', 'N/A')}\")\n    print(f\"\\nFeatures identified: {len(qwen_understanding.get('features', []))}\")\n    for f in qwen_understanding.get('features', [])[:10]:\n        print(f\"  - {f.get('type')}: {f.get('callout', f.get('description', ''))}\")\nelse:\n    print(f\"Parse error: {qwen_understanding.get('parse_error')}\")\n\n# === ANALYSIS 2: Drawing Quality Audit ===\nquality_prompt = \"\"\"Examine this engineering drawing for completeness and best practices. Return a JSON object with:\n\n{\n  \"titleBlockCompleteness\": {\n    \"hasPartNumber\": true/false,\n    \"partNumberValue\": \"the part number if visible\",\n    \"hasDescription\": true/false,\n    \"descriptionValue\": \"the description if visible\",\n    \"hasMaterial\": true/false,\n    \"materialValue\": \"the material if visible\",\n    \"hasRevision\": true/false,\n    \"revisionValue\": \"the revision if visible\",\n    \"hasScale\": true/false,\n    \"scaleValue\": \"the scale if visible\",\n    \"hasDate\": true/false,\n    \"dateValue\": \"the date if visible\",\n    \"hasDrawnBy\": true/false,\n    \"drawnByValue\": \"name if visible\",\n    \"hasApprovedBy\": true/false,\n    \"approvedByValue\": \"name if visible\"\n  },\n  \"drawingQuality\": {\n    \"viewsLabeled\": true/false,\n    \"viewsLabeledComment\": \"are views clearly labeled (FRONT, TOP, etc)?\",\n    \"dimensionsReadable\": true/false,\n    \"dimensionsComment\": \"are dimensions clear and not overlapping?\",\n    \"tolerancesPresent\": true/false,\n    \"tolerancesComment\": \"are tolerances specified on critical dimensions?\",\n    \"surfaceFinishSpecified\": true/false,\n    \"surfaceFinishComment\": \"is surface finish callout present?\",\n    \"generalToleranceBlock\": true/false,\n    \"generalToleranceComment\": \"is there a general tolerance note/block?\",\n    \"thirdAngleProjection\": true/false,\n    \"projectionComment\": \"is projection symbol visible (third angle)?\",\n    \"unitsSpecified\": true/false,\n    \"unitsValue\": \"INCHES or MM if specified\"\n  },\n  \"overallAssessment\": {\n    \"completenessScore\": \"1-10 rating\",\n    \"majorIssues\": [\"list any major issues found\"],\n    \"minorIssues\": [\"list any minor issues found\"],\n    \"recommendations\": [\"suggestions for improvement\"]\n  }\n}\n\nBe thorough and critical - this is a quality audit. Only return valid JSON, no other text.\"\"\"\n\nprint(\"\\nRunning drawing quality audit with Qwen2.5-VL...\")\ndrawing_quality = run_qwen_analysis(artifacts[0].image, quality_prompt)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"QWEN2.5-VL DRAWING QUALITY AUDIT\")\nprint(\"=\"*50)\n\nif \"parse_error\" not in drawing_quality:\n    tb = drawing_quality.get('titleBlockCompleteness', {})\n    dq = drawing_quality.get('drawingQuality', {})\n    oa = drawing_quality.get('overallAssessment', {})\n\n    print(\"\\nTitle Block:\")\n    print(f\"  Part Number: {'\u2713' if tb.get('hasPartNumber') else '\u2717'} {tb.get('partNumberValue', '')}\")\n    print(f\"  Description: {'\u2713' if tb.get('hasDescription') else '\u2717'} {tb.get('descriptionValue', '')[:30] if tb.get('descriptionValue') else ''}\")\n    print(f\"  Material:    {'\u2713' if tb.get('hasMaterial') else '\u2717'} {tb.get('materialValue', '')}\")\n    print(f\"  Revision:    {'\u2713' if tb.get('hasRevision') else '\u2717'} {tb.get('revisionValue', '')}\")\n    print(f\"  Scale:       {'\u2713' if tb.get('hasScale') else '\u2717'} {tb.get('scaleValue', '')}\")\n    print(f\"  Date:        {'\u2713' if tb.get('hasDate') else '\u2717'} {tb.get('dateValue', '')}\")\n\n    print(\"\\nDrawing Quality:\")\n    print(f\"  Views Labeled:     {'\u2713' if dq.get('viewsLabeled') else '\u2717'}\")\n    print(f\"  Dims Readable:     {'\u2713' if dq.get('dimensionsReadable') else '\u2717'}\")\n    print(f\"  Tolerances:        {'\u2713' if dq.get('tolerancesPresent') else '\u2717'}\")\n    print(f\"  Surface Finish:    {'\u2713' if dq.get('surfaceFinishSpecified') else '\u2717'}\")\n    print(f\"  General Tol Block: {'\u2713' if dq.get('generalToleranceBlock') else '\u2717'}\")\n\n    print(f\"\\nOverall Score: {oa.get('completenessScore', 'N/A')}/10\")\nelse:\n    print(f\"Parse error: {drawing_quality.get('parse_error')}\")\n    drawing_quality = {}\n\n# === ANALYSIS 3: BOM Extraction (for assembly drawings) ===\nbom_prompt = \"\"\"Look at this engineering drawing. If there is a Bill of Materials (BOM) or Parts List table visible, extract it. Return a JSON object:\n\n{\n  \"hasBOM\": true/false,\n  \"bomLocation\": \"where on the drawing (e.g., upper right, separate sheet)\",\n  \"bomItems\": [\n    {\n      \"itemNumber\": \"1\",\n      \"partNumber\": \"the part number\",\n      \"description\": \"part description\",\n      \"quantity\": 1,\n      \"material\": \"if specified in BOM\"\n    }\n  ],\n  \"totalItems\": 0,\n  \"bomNotes\": \"any notes about the BOM (e.g., 'items not shown', 'see sheet 2')\"\n}\n\nIf there is NO BOM or Parts List visible, return:\n{\n  \"hasBOM\": false,\n  \"bomLocation\": null,\n  \"bomItems\": [],\n  \"totalItems\": 0,\n  \"bomNotes\": \"No BOM found - this appears to be a detail/part drawing\"\n}\n\nOnly return valid JSON, no other text.\"\"\"\n\nprint(\"\\nExtracting BOM (if present) with Qwen2.5-VL...\")\nbom_data = run_qwen_analysis(artifacts[0].image, bom_prompt)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"QWEN2.5-VL BOM EXTRACTION\")\nprint(\"=\"*50)\n\nif \"parse_error\" not in bom_data:\n    if bom_data.get('hasBOM'):\n        print(f\"BOM Found: Yes ({bom_data.get('bomLocation', 'location unknown')})\")\n        print(f\"Total Items: {bom_data.get('totalItems', len(bom_data.get('bomItems', [])))}\")\n        print(\"\\nBOM Items:\")\n        for item in bom_data.get('bomItems', [])[:10]:\n            print(f\"  {item.get('itemNumber', '?')}. {item.get('partNumber', 'N/A')} - {item.get('description', 'N/A')} (Qty: {item.get('quantity', 1)})\")\n        if bom_data.get('bomNotes'):\n            print(f\"\\nNotes: {bom_data.get('bomNotes')}\")\n    else:\n        print(\"BOM Found: No\")\n        print(f\"Note: {bom_data.get('bomNotes', 'This appears to be a part drawing without BOM')}\")\nelse:\n    print(f\"Parse error: {bom_data.get('parse_error')}\")\n    bom_data = {\"hasBOM\": False, \"bomItems\": [], \"bomNotes\": \"Parse error\"}\n\n# === ANALYSIS 4: Manufacturing Notes Extraction ===\nmfg_prompt = \"\"\"Examine this engineering drawing for manufacturing-related notes and specifications. Return a JSON object:\n\n{\n  \"hasManufacturingNotes\": true/false,\n  \"heatTreatment\": {\n    \"specified\": true/false,\n    \"specification\": \"e.g., HEAT TREAT TO 58-62 HRC\",\n    \"hardness\": \"e.g., 58-62 HRC\",\n    \"process\": \"e.g., carburize, through harden, case harden\"\n  },\n  \"surfaceFinish\": {\n    \"specified\": true/false,\n    \"generalFinish\": \"e.g., 125 RMS, 63 Ra\",\n    \"specificFinishes\": [\n      {\"surface\": \"bore\", \"finish\": \"32 Ra\"},\n      {\"surface\": \"OD\", \"finish\": \"63 Ra\"}\n    ]\n  },\n  \"platingOrCoating\": {\n    \"specified\": true/false,\n    \"type\": \"e.g., ZINC PLATE, ANODIZE, PAINT BLACK, POWDER COAT\",\n    \"specification\": \"e.g., PER MIL-C-5541, CLASS 2\",\n    \"thickness\": \"if specified\"\n  },\n  \"weldingNotes\": {\n    \"specified\": true/false,\n    \"weldSpec\": \"e.g., AWS D1.1\",\n    \"weldTypes\": [\"fillet\", \"groove\", \"spot\"],\n    \"notes\": \"any welding-specific notes\"\n  },\n  \"specialProcesses\": [\n    {\n      \"process\": \"e.g., stress relieve, shot peen, passivate\",\n      \"specification\": \"details if given\"\n    }\n  ],\n  \"inspectionRequirements\": {\n    \"specified\": true/false,\n    \"requirements\": [\"e.g., 100% INSPECT THREADS\", \"CMM REQUIRED\", \"FIRST ARTICLE\"]\n  },\n  \"generalNotes\": [\n    \"REMOVE ALL BURRS AND SHARP EDGES\",\n    \"BREAK EDGES .005-.015\",\n    \"any other manufacturing notes\"\n  ],\n  \"certifications\": [\"e.g., MATERIAL CERT REQUIRED\", \"PPAP REQUIRED\"]\n}\n\nExtract ALL manufacturing-related information visible on the drawing. If a category has no information, set specified to false.\nOnly return valid JSON, no other text.\"\"\"\n\nprint(\"\\nExtracting manufacturing notes with Qwen2.5-VL...\")\nmfg_notes = run_qwen_analysis(artifacts[0].image, mfg_prompt)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"QWEN2.5-VL MANUFACTURING NOTES\")\nprint(\"=\"*50)\n\nif \"parse_error\" not in mfg_notes:\n    ht = mfg_notes.get('heatTreatment', {})\n    sf = mfg_notes.get('surfaceFinish', {})\n    pc = mfg_notes.get('platingOrCoating', {})\n    wn = mfg_notes.get('weldingNotes', {})\n\n    print(f\"\\nHeat Treatment: {'\u2713 ' + ht.get('specification', '') if ht.get('specified') else '\u2717 Not specified'}\")\n    print(f\"Surface Finish: {'\u2713 ' + sf.get('generalFinish', '') if sf.get('specified') else '\u2717 Not specified'}\")\n    print(f\"Plating/Coating: {'\u2713 ' + pc.get('type', '') if pc.get('specified') else '\u2717 Not specified'}\")\n    print(f\"Welding Notes: {'\u2713 ' + wn.get('weldSpec', '') if wn.get('specified') else '\u2717 Not specified'}\")\n\n    if mfg_notes.get('specialProcesses'):\n        print(\"\\nSpecial Processes:\")\n        for sp in mfg_notes.get('specialProcesses', []):\n            print(f\"  - {sp.get('process', 'Unknown')}\")\n\n    if mfg_notes.get('generalNotes'):\n        print(\"\\nGeneral Notes:\")\n        for note in mfg_notes.get('generalNotes', [])[:5]:\n            print(f\"  - {note}\")\n\n    if mfg_notes.get('inspectionRequirements', {}).get('specified'):\n        print(\"\\nInspection Requirements:\")\n        for req in mfg_notes.get('inspectionRequirements', {}).get('requirements', []):\n            print(f\"  - {req}\")\nelse:\n    print(f\"Parse error: {mfg_notes.get('parse_error')}\")\n    mfg_notes = {\"hasManufacturingNotes\": False}\n\n# Save all analyses\nunderstanding_out = os.path.join(OUTPUT_DIR, \"QwenUnderstanding.json\")\nwith open(understanding_out, 'w') as f:\n    json.dump({\n        'featureAnalysis': qwen_understanding,\n        'qualityAudit': drawing_quality,\n        'bomExtraction': bom_data,\n        'manufacturingNotes': mfg_notes\n    }, f, indent=2)\nprint(f\"\\nSaved: {understanding_out}\")",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 503,
     "referenced_widgets": [
      "f8742eb41fab497ba281655192a114ac",
      "e3f65c48467542e58565542cca30c9d5",
      "ef098d0d1aa245dca3b97ebcd632627d",
      "b1544a4969d644569fb7b97067b3d590",
      "74bdac0bd1e041538b3039e0e8c683a8",
      "5363bb466f9f4045bb35ce729d8317e6",
      "f86bf2be7cca40419a7f6b919c398a13",
      "fba7d3fa3b1d4d1ea981a0465d151f85",
      "fb6e931eed134e05b2f1f899b1c9e011",
      "ffd58f4bba81420aac5af57e13e2274d",
      "219c366a577644fb94db7eab6b876436",
      "62cd9f11297c4f77b227e5a963718ca6",
      "c24a9305fa054ab4a35277ac4ab2bb86",
      "c695847144ec4cb799f7697408cfe0b2",
      "aad9aa0b59e942658e5f570772bf1076",
      "13145392bc1c44319cec4ba35e940ac8",
      "ccd34443ff1d4a25b0a84d80e5369b63",
      "c02b293403eb4f9fac7ad10324ffdd97",
      "7044cbb302af47d890c40d227f082a7b",
      "8994eb13c8284d09b0a236fae93a3860",
      "8c49e459cf6344e79f9bf78d64610ae5",
      "cd7f7fb3ea104fb8a49565c7147991c9",
      "1bfe08e7fd0a47ec8a8c3a1407c340b0",
      "d6c7690cbd0f4b0e8192f77bdcbfca45",
      "8e0e99b5da574536aeb20d2281ce177b",
      "3c258c3522884e05b9332e90f11ca60d",
      "9f526fcbaca743648f17cd567f384975",
      "b647c233f0904a628d8c2ac27cedf304",
      "3eca00b628d84d4ea0ab22cf9d9a0e49",
      "1fbab13f6c83494cac016e8b18ffaa67",
      "9641a756a7ae47d98ab2ddcf665a4ce8",
      "9cc1cd6f1fbf4c1c929d6d3857d63b6c",
      "579efa5e128a4881bcc7f3c172d17db3",
      "39f1402a91ac4f16a539abfbe7a6d744",
      "c327d834e69a4a8093e167c888e4b631",
      "f01a8c4705b84bfc95d90a4e33ff31e4",
      "55ebd7e73d85471aa079f92c61b05bb7",
      "c944c0e378c041c5b924924c0a795ed5",
      "b0520cd694dc45499cb83555559e9877",
      "f57dd0de6cdb4f29b0aa60ba92f6f5c9",
      "341fae84019b4d398d998628f250300c",
      "8f94dc08de5247e8a6930e100f7a6d1f",
      "092726aebeb04d60812e95f055ac5b3c",
      "1cb95142cec545beb7d0b3bc5cab44cd"
     ]
    },
    "id": "IZg8-vwCYxps",
    "outputId": "3e70c417-4c08-48ac-c19c-4e341b372084"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 11: Merge OCR + Qwen Understanding into Enriched Evidence\n# All dimensions in INCHES (matching drawing callouts)\n\n# Regex patterns for extracting callouts from OCR\nPATTERNS = {\n    'metric_thread': r'M(\\d+(?:\\.\\d+)?)\\s*[xX]\\s*(\\d+(?:\\.\\d+)?)',\n    'imperial_thread': r'(\\d+/\\d+)\\s*-\\s*(\\d+)',\n    'thru_hole': r'[oO\u00d8\u2205\u03c6]?\\s*(\\.?\\d+\\.?\\d*|\\d+)\\s*(?:mm|MM|\")?\\s*THRU',\n    'blind_hole': r'[oO\u00d8\u2205\u03c6]?\\s*(\\.?\\d+\\.?\\d*|\\d+)\\s*[xX]\\s*(\\d+\\.?\\d*)\\s*(?:DEEP|DP)',\n    'fillet': r'\\bR(\\d+\\.?\\d*)\\b',\n    'chamfer': r'(\\d+\\.?\\d*)\\s*[xX]\\s*45\\s*[\u00b0]?',\n}\n\ndef parse_ocr_callouts(ocr_lines: List[str]) -> List[Dict]:\n    \"\"\"Extract callouts from OCR text. Hole diameters stored in inches (as-is from drawing).\"\"\"\n    callouts = []\n    raw_text = \"\\n\".join(ocr_lines)\n\n    # Metric threads (M6x1.0) - keep in metric\n    for match in re.finditer(PATTERNS['metric_thread'], raw_text, re.IGNORECASE):\n        callouts.append({\n            'calloutType': 'TappedHole',\n            'thread': {'standard': 'Metric', 'nominalDiameterMm': float(match.group(1)), 'pitch': float(match.group(2))},\n            'raw': match.group(0), 'source': 'ocr'\n        })\n\n    # Through holes - store diameter in inches (no conversion)\n    for match in re.finditer(PATTERNS['thru_hole'], raw_text, re.IGNORECASE):\n        raw = match.group(0)\n        val = float(match.group(1))\n        callouts.append({\n            'calloutType': 'Hole',\n            'diameterInches': val,  # Keep as inches\n            'isThrough': True,\n            'raw': raw,\n            'source': 'ocr'\n        })\n\n    # Fillets - store in inches\n    for match in re.finditer(PATTERNS['fillet'], raw_text, re.IGNORECASE):\n        raw = match.group(0)\n        val = float(match.group(1))\n        callouts.append({\n            'calloutType': 'Fillet',\n            'radiusInches': val,\n            'raw': raw,\n            'source': 'ocr'\n        })\n\n    # Chamfers - store in inches\n    for match in re.finditer(PATTERNS['chamfer'], raw_text, re.IGNORECASE):\n        raw = match.group(0)\n        val = float(match.group(1))\n        callouts.append({\n            'calloutType': 'Chamfer',\n            'distance1Inches': val,\n            'angleDegrees': 45,\n            'raw': raw,\n            'source': 'ocr'\n        })\n\n    return callouts\n\ndef parse_qwen_features(qwen_data: Dict) -> List[Dict]:\n    \"\"\"Convert Qwen features to callout format. Dimensions in inches.\"\"\"\n    callouts = []\n    if \"parse_error\" in qwen_data:\n        return callouts\n\n    type_map = {\n        'TappedHole': 'TappedHole', 'ThroughHole': 'Hole', 'BlindHole': 'Hole',\n        'Counterbore': 'Hole', 'Countersink': 'Hole', 'Fillet': 'Fillet',\n        'Chamfer': 'Chamfer', 'Thread': 'TappedHole', 'Slot': 'Slot'\n    }\n\n    # Filter out general notes misclassified as features\n    note_keywords = ['REMOVE ALL BURRS', 'BREAK SHARP EDGES', 'DEBURR', 'CLEAN']\n\n    for feat in qwen_data.get('features', []):\n        ftype = feat.get('type', '')\n        callout_type = type_map.get(ftype, ftype)\n        callout = feat.get('callout', '')\n        qty = feat.get('quantity', 1)\n\n        # Skip if this looks like a general note, not a feature\n        if any(kw in callout.upper() for kw in note_keywords):\n            continue\n\n        entry = {\n            'calloutType': callout_type,\n            'description': feat.get('description', ''),\n            'location': feat.get('location', ''),\n            'quantity': qty,\n            'raw': callout,\n            'source': 'qwen'\n        }\n\n        # Try to parse dimensions from Qwen's callout text\n        if callout:\n            # Metric threads\n            thread_match = re.search(r'M(\\d+(?:\\.\\d+)?)[xX](\\d+(?:\\.\\d+)?)', callout)\n            if thread_match:\n                entry['thread'] = {\n                    'standard': 'Metric',\n                    'nominalDiameterMm': float(thread_match.group(1)),\n                    'pitch': float(thread_match.group(2))\n                }\n\n            # Hole diameters - keep in inches\n            hole_match = re.search(r'[oO\u00d8\u2205\u03c6]?\\s*(\\.?\\d+\\.?\\d*)', callout)\n            if hole_match and callout_type == 'Hole':\n                val = float(hole_match.group(1))\n                entry['diameterInches'] = val\n                entry['isThrough'] = 'THRU' in callout.upper()\n\n        callouts.append(entry)\n\n    return callouts\n\ndef merge_evidence(ocr_callouts: List[Dict], qwen_callouts: List[Dict]) -> List[Dict]:\n    \"\"\"Merge OCR and Qwen callouts, preferring OCR for dimensions but using Qwen for context.\"\"\"\n    merged = []\n    used_qwen = set()\n\n    for ocr in ocr_callouts:\n        merged_entry = ocr.copy()\n        merged_entry['sources'] = ['ocr']\n\n        # Try to find matching Qwen feature for additional context\n        for qi, qwen in enumerate(qwen_callouts):\n            if qi in used_qwen:\n                continue\n            if ocr.get('calloutType') == qwen.get('calloutType'):\n                # Check if dimensions roughly match\n                if ocr.get('thread') and qwen.get('thread'):\n                    if ocr['thread'].get('nominalDiameterMm') == qwen['thread'].get('nominalDiameterMm'):\n                        merged_entry['location'] = qwen.get('location', '')\n                        merged_entry['description'] = qwen.get('description', '')\n                        merged_entry['sources'].append('qwen')\n                        used_qwen.add(qi)\n                        break\n                elif ocr.get('diameterInches') and qwen.get('diameterInches'):\n                    # Compare in inches with 0.01\" tolerance\n                    if abs(ocr['diameterInches'] - qwen['diameterInches']) < 0.01:\n                        merged_entry['location'] = qwen.get('location', '')\n                        merged_entry['description'] = qwen.get('description', '')\n                        merged_entry['sources'].append('qwen')\n                        used_qwen.add(qi)\n                        break\n\n        merged.append(merged_entry)\n\n    # Add Qwen features not matched to OCR (may be features OCR missed)\n    for qi, qwen in enumerate(qwen_callouts):\n        if qi not in used_qwen:\n            qwen['sources'] = ['qwen_only']\n            merged.append(qwen)\n\n    return merged\n\n# Parse both sources\nocr_callouts = parse_ocr_callouts(ocr_lines)\nqwen_callouts = parse_qwen_features(qwen_understanding)\n\n# Merge\nmerged_callouts = merge_evidence(ocr_callouts, qwen_callouts)\n\n# Build enriched evidence\nevidence = {\n    'schemaVersion': '1.4.0',  # Updated: now uses inches\n    'partNumber': part_identity.partNumber,\n    'extractedAt': datetime.now().isoformat() + 'Z',\n    'units': 'inches',  # Explicit unit declaration\n    'sources': {\n        'ocr': {'model': 'LightOnOCR-2-1B', 'lineCount': len(ocr_lines)},\n        'vision': {'model': 'Qwen2.5-VL-7B', 'featureCount': len(qwen_callouts)}\n    },\n    'drawingInfo': {\n        'views': qwen_understanding.get('views', []),\n        'partDescription': qwen_understanding.get('partDescription', ''),\n        'material': qwen_understanding.get('material', ''),\n        'titleBlock': qwen_understanding.get('titleBlockInfo', {}),\n        'notes': qwen_understanding.get('notes', [])\n    },\n    'foundCallouts': merged_callouts,\n    'rawOcrSample': ocr_lines[:15]\n}\n\nprint(\"=\"*50)\nprint(\"MERGED DRAWING EVIDENCE (inches)\")\nprint(\"=\"*50)\nprint(f\"OCR callouts:   {len(ocr_callouts)}\")\nprint(f\"Qwen features:  {len(qwen_callouts)}\")\nprint(f\"Merged total:   {len(merged_callouts)}\")\nprint(f\"\\nDrawing info:\")\nprint(f\"  Views: {evidence['drawingInfo']['views']}\")\nprint(f\"  Material: {evidence['drawingInfo']['material']}\")\nprint(f\"\\nMerged callouts:\")\nfor c in merged_callouts[:10]:\n    sources = '+'.join(c.get('sources', []))\n    extra = f\" [{sources}]\"\n    if c.get('location'):\n        extra += f\" @ {c['location']}\"\n    print(f\"  {c['calloutType']}: {c.get('raw', c.get('description', ''))}{extra}\")\n\n# Save\nevidence_out = os.path.join(OUTPUT_DIR, \"DrawingEvidence.json\")\nwith open(evidence_out, 'w') as f:\n    json.dump(evidence, f, indent=2)\nprint(f\"\\nSaved: {evidence_out}\")",
   "metadata": {
    "id": "3ZlPb5FJQBHV",
    "outputId": "75fde05a-ab49-4f51-b9fa-8fd95e43541b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 12: Generate DiffResult (comparison in INCHES)\n\ndef extract_sw_requirements(sw_data: Dict) -> List[Dict]:\n    \"\"\"Extract requirements from SolidWorks JSON using comparison.holeGroups.\n    Returns hole diameters in INCHES for direct comparison with drawing callouts.\"\"\"\n    requirements = []\n\n    # Primary source: comparison.holeGroups (reconciled/canonical data)\n    comparison = sw_data.get('comparison', {})\n    hole_groups = comparison.get('holeGroups', [])\n\n    for hg in hole_groups:\n        hole_type = hg.get('holeType', '')\n        canonical = hg.get('canonical', '')\n        count = hg.get('count', 1)\n        diameters = hg.get('diameters', {})\n        thread = hg.get('thread', {})\n\n        if hole_type == 'Tapped':\n            # Tapped hole - thread info stays in metric (M6x1.0)\n            requirements.append({\n                'type': 'TappedHole',\n                'thread': {\n                    'standard': thread.get('standard', 'Metric'),\n                    'nominalDiameterMm': thread.get('majorDiameterMm') or diameters.get('threadNominalDiameterMm'),\n                    'pitch': thread.get('pitch'),\n                    'callout': thread.get('callout', canonical)\n                },\n                'count': count,\n                'canonical': canonical,\n                'source': 'sw_comparison.holeGroups'\n            })\n        elif hole_type == 'Through':\n            # Plain through hole - use INCHES for comparison\n            diameter_inches = diameters.get('pilotOrTapDrillDiameterInches')\n            requirements.append({\n                'type': 'Hole',\n                'diameterInches': diameter_inches,\n                'isThrough': True,\n                'count': count,\n                'canonical': canonical,\n                'canonicalInches': diameters.get('nearestStandardInch', ''),\n                'source': 'sw_comparison.holeGroups'\n            })\n        elif hole_type == 'Blind':\n            # Blind hole - use INCHES\n            diameter_inches = diameters.get('pilotOrTapDrillDiameterInches')\n            requirements.append({\n                'type': 'Hole',\n                'diameterInches': diameter_inches,\n                'isThrough': False,\n                'count': count,\n                'canonical': canonical,\n                'source': 'sw_comparison.holeGroups'\n            })\n\n    # Fallback: features.holeWizardHoles if no comparison data\n    if not requirements:\n        features = sw_data.get('features', {})\n        for hole in features.get('holeWizardHoles', []):\n            if hole.get('isTapped'):\n                thread_size = hole.get('threadSize', '')\n                m = re.match(r'M(\\d+(?:\\.\\d+)?)[xX](\\d+(?:\\.\\d+)?)', thread_size)\n                if m:\n                    requirements.append({\n                        'type': 'TappedHole',\n                        'thread': {\n                            'standard': 'Metric',\n                            'nominalDiameterMm': float(m.group(1)),\n                            'pitch': float(m.group(2)),\n                            'callout': thread_size\n                        },\n                        'count': hole.get('instanceCount', 1),\n                        'source': 'sw_features.holeWizardHoles'\n                    })\n            else:\n                # Convert meters to inches\n                diameter_m = hole.get('diameter', 0)\n                diameter_inches = diameter_m * 39.3701\n                requirements.append({\n                    'type': 'Hole',\n                    'diameterInches': diameter_inches,\n                    'isThrough': hole.get('isThrough', False),\n                    'count': hole.get('instanceCount', 1),\n                    'source': 'sw_features.holeWizardHoles'\n                })\n\n        # Fillets - convert to inches\n        for fillet in features.get('fillets', []):\n            radius_mm = fillet.get('radius', 0)\n            requirements.append({\n                'type': 'Fillet',\n                'radiusInches': radius_mm / 25.4 if radius_mm else 0,\n                'source': 'sw_features'\n            })\n\n        # Chamfers - convert to inches\n        for chamfer in features.get('chamfers', []):\n            dist_mm = chamfer.get('distance1', 0)\n            requirements.append({\n                'type': 'Chamfer',\n                'distance1Inches': dist_mm / 25.4 if dist_mm else 0,\n                'angleDegrees': chamfer.get('angle', 45),\n                'source': 'sw_features'\n            })\n\n    return requirements\n\ndef compare_callout_to_requirement(callout: Dict, req: Dict, tolerance_inches: float = 0.015) -> bool:\n    \"\"\"Check if a drawing callout matches a SW requirement.\n    Hole comparison done in INCHES with 0.015\\\" tolerance (~0.4mm).\"\"\"\n    ctype = callout.get('calloutType')\n    rtype = req.get('type')\n\n    if ctype != rtype:\n        return False\n\n    if ctype == 'Hole':\n        # Compare in INCHES\n        d1 = callout.get('diameterInches', 0)\n        d2 = req.get('diameterInches', 0)\n        if d1 and d2 and abs(d1 - d2) <= tolerance_inches:\n            return True\n\n    elif ctype == 'TappedHole':\n        # Metric threads - compare in mm\n        t1 = callout.get('thread', {})\n        t2 = req.get('thread', {})\n        nom1 = t1.get('nominalDiameterMm', 0)\n        nom2 = t2.get('nominalDiameterMm', 0)\n        if nom1 and nom2 and abs(nom1 - nom2) < 0.1:\n            p1 = t1.get('pitch')\n            p2 = t2.get('pitch')\n            if p1 and p2:\n                return abs(p1 - p2) < 0.01\n            return True\n\n    elif ctype == 'Fillet':\n        r1 = callout.get('radiusInches', 0)\n        r2 = req.get('radiusInches', 0)\n        if r1 and r2 and abs(r1 - r2) <= tolerance_inches:\n            return True\n\n    elif ctype == 'Chamfer':\n        d1 = callout.get('distance1Inches', 0)\n        d2 = req.get('distance1Inches', 0)\n        if d1 and d2 and abs(d1 - d2) <= tolerance_inches:\n            return True\n\n    return False\n\ndef generate_diff_result(evidence: Dict, sw_data: Dict) -> Dict:\n    \"\"\"Compare drawing evidence against SolidWorks requirements (in inches).\"\"\"\n    callouts = evidence.get('foundCallouts', [])\n    requirements = extract_sw_requirements(sw_data)\n\n    found = []\n    missing = []\n    matched_callouts = set()\n    matched_requirements = set()\n\n    # Check each requirement against callouts\n    for ri, req in enumerate(requirements):\n        match_found = False\n        for ci, callout in enumerate(callouts):\n            if ci not in matched_callouts and compare_callout_to_requirement(callout, req):\n                found.append({\n                    'status': 'FOUND',\n                    'requirement': req,\n                    'evidence': callout,\n                    'note': f\"Matched: {req.get('canonical', req.get('type'))}\"\n                })\n                matched_callouts.add(ci)\n                matched_requirements.add(ri)\n                match_found = True\n                break\n\n        if not match_found:\n            missing.append({\n                'status': 'MISSING',\n                'requirement': req,\n                'evidence': None,\n                'note': f\"Not found in drawing: {req.get('canonical', req.get('type'))}\"\n            })\n\n    # Extra callouts not matched to any requirement\n    extra = []\n    for ci, callout in enumerate(callouts):\n        if ci not in matched_callouts:\n            extra.append({\n                'status': 'EXTRA',\n                'requirement': None,\n                'evidence': callout,\n                'note': f\"In drawing but not in SW: {callout.get('raw', callout.get('calloutType'))}\"\n            })\n\n    diff_result = {\n        'partNumber': evidence.get('partNumber'),\n        'generatedAt': datetime.now().isoformat() + 'Z',\n        'units': 'inches',\n        'summary': {\n            'totalRequirements': len(requirements),\n            'found': len(found),\n            'missing': len(missing),\n            'extra': len(extra),\n            'matchRate': f\"{len(found)/len(requirements)*100:.1f}%\" if requirements else \"N/A\"\n        },\n        'details': {\n            'found': found,\n            'missing': missing,\n            'extra': extra\n        }\n    }\n\n    return diff_result\n\n# Load SW data and generate diff\nif part_identity.swJsonPath:\n    sw_data, err = load_json_robust(part_identity.swJsonPath)\n    if sw_data:\n        # Show what we're extracting\n        requirements = extract_sw_requirements(sw_data)\n        print(\"=\"*50)\n        print(\"SW REQUIREMENTS EXTRACTED (inches)\")\n        print(\"=\"*50)\n        for req in requirements:\n            if req['type'] == 'Hole':\n                print(f\"  {req['type']}: \u00f8{req.get('diameterInches', 0):.4f}\\\" ({req.get('canonical', '')})\")\n            else:\n                print(f\"  {req['type']}: {req.get('canonical', req.get('thread', {}).get('callout', ''))}\")\n\n        diff_result = generate_diff_result(evidence, sw_data)\n\n        print(\"\\n\" + \"=\"*50)\n        print(\"DIFF RESULT\")\n        print(\"=\"*50)\n        print(f\"Part: {diff_result['partNumber']}\")\n        print(f\"  Total Requirements: {diff_result['summary']['totalRequirements']}\")\n        print(f\"  FOUND:   {diff_result['summary']['found']}\")\n        print(f\"  MISSING: {diff_result['summary']['missing']}\")\n        print(f\"  EXTRA:   {diff_result['summary']['extra']}\")\n        print(f\"  Match Rate: {diff_result['summary']['matchRate']}\")\n\n        if diff_result['details']['found']:\n            print(\"\\nMatched:\")\n            for item in diff_result['details']['found']:\n                print(f\"  \u2713 {item['note']}\")\n\n        if diff_result['details']['missing']:\n            print(\"\\nMissing from drawing:\")\n            for item in diff_result['details']['missing']:\n                print(f\"  \u2717 {item['note']}\")\n\n        if diff_result['details']['extra']:\n            print(\"\\nExtra in drawing:\")\n            for item in diff_result['details']['extra']:\n                print(f\"  ? {item['note']}\")\n\n        # Save\n        diff_out = os.path.join(OUTPUT_DIR, \"DiffResult.json\")\n        with open(diff_out, 'w') as f:\n            json.dump(diff_result, f, indent=2)\n        print(f\"\\nSaved: {diff_out}\")\n    else:\n        print(f\"Error loading SW JSON: {err}\")\nelse:\n    print(\"No SW JSON path - cannot generate diff\")",
   "metadata": {
    "id": "eZuYl-gdQBHV",
    "outputId": "a92d7f7d-e8a4-4cc2-ac38-0b0ccb3fa837",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Cell 13: Generate QC Report with GPT-4o-mini\nfrom openai import OpenAI\nfrom google.colab import userdata\n\n# Get OpenAI API key from Colab secrets\ntry:\n    openai_api_key = userdata.get('OPENAI_API_KEY')\nexcept:\n    openai_api_key = None\n\nif not openai_api_key:\n    print(\"WARNING: OPENAI_API_KEY not found in Colab secrets.\")\n    print(\"Add it via: Runtime > Secrets > Add new secret\")\n    print(\"Skipping GPT-4o-mini report generation.\")\nelse:\n    client = OpenAI(api_key=openai_api_key)\n\n    def generate_qc_report(diff_result: Dict, evidence: Dict, sw_data: Dict,\n                           drawing_quality: Dict, bom_data: Dict, mfg_notes: Dict) -> str:\n        \"\"\"Use GPT-4o-mini to generate a comprehensive QC report.\"\"\"\n\n        # Build context for the LLM\n        part_number = diff_result.get('partNumber', 'Unknown')\n        summary = diff_result.get('summary', {})\n        details = diff_result.get('details', {})\n\n        # Part info\n        identity = sw_data.get('identity', {})\n        part_desc = identity.get('description', evidence.get('drawingInfo', {}).get('partDescription', ''))\n        material = identity.get('material', evidence.get('drawingInfo', {}).get('material', ''))\n\n        # Format found items\n        found_items = []\n        for item in details.get('found', []):\n            req = item.get('requirement', {})\n            ev = item.get('evidence', {})\n            if req.get('type') == 'TappedHole':\n                thread = req.get('thread', {})\n                found_items.append(f\"- {thread.get('callout', 'Thread')} (count: {req.get('count', 1)}) - Drawing shows: {ev.get('raw', 'N/A')}\")\n            elif req.get('type') == 'Hole':\n                found_items.append(f\"- \u00f8{req.get('diameterInches', 0):.4f}\\\" {'THRU' if req.get('isThrough') else 'BLIND'} (count: {req.get('count', 1)}) - Drawing shows: {ev.get('raw', 'N/A')}\")\n            else:\n                found_items.append(f\"- {req.get('type')}: {req.get('canonical', 'N/A')} - Drawing shows: {ev.get('raw', 'N/A')}\")\n\n        # Format missing items\n        missing_items = []\n        for item in details.get('missing', []):\n            req = item.get('requirement', {})\n            if req.get('type') == 'TappedHole':\n                thread = req.get('thread', {})\n                missing_items.append(f\"- {thread.get('callout', 'Thread')} (count: {req.get('count', 1)})\")\n            elif req.get('type') == 'Hole':\n                missing_items.append(f\"- \u00f8{req.get('diameterInches', 0):.4f}\\\" {'THRU' if req.get('isThrough') else 'BLIND'} (count: {req.get('count', 1)})\")\n            else:\n                missing_items.append(f\"- {req.get('type')}: {req.get('canonical', 'N/A')}\")\n\n        # Format extra items\n        extra_items = []\n        for item in details.get('extra', []):\n            ev = item.get('evidence', {})\n            extra_items.append(f\"- {ev.get('calloutType', 'Unknown')}: {ev.get('raw', 'N/A')}\")\n\n        # Drawing notes\n        drawing_notes = evidence.get('drawingInfo', {}).get('notes', [])\n\n        # === DRAWING QUALITY AUDIT DATA ===\n        tb = drawing_quality.get('titleBlockCompleteness', {})\n        dq = drawing_quality.get('drawingQuality', {})\n        oa = drawing_quality.get('overallAssessment', {})\n\n        # Title block checklist\n        title_block_items = []\n        title_block_items.append(f\"- Part Number: {'\u2713 Present' if tb.get('hasPartNumber') else '\u2717 MISSING'} - {tb.get('partNumberValue', 'N/A')}\")\n        title_block_items.append(f\"- Description: {'\u2713 Present' if tb.get('hasDescription') else '\u2717 MISSING'} - {tb.get('descriptionValue', 'N/A')[:50] if tb.get('descriptionValue') else 'N/A'}\")\n        title_block_items.append(f\"- Material: {'\u2713 Present' if tb.get('hasMaterial') else '\u2717 MISSING'} - {tb.get('materialValue', 'N/A')}\")\n        title_block_items.append(f\"- Revision: {'\u2713 Present' if tb.get('hasRevision') else '\u2717 MISSING'} - {tb.get('revisionValue', 'N/A')}\")\n        title_block_items.append(f\"- Scale: {'\u2713 Present' if tb.get('hasScale') else '\u2717 MISSING'} - {tb.get('scaleValue', 'N/A')}\")\n        title_block_items.append(f\"- Date: {'\u2713 Present' if tb.get('hasDate') else '\u2717 MISSING'} - {tb.get('dateValue', 'N/A')}\")\n        title_block_items.append(f\"- Drawn By: {'\u2713 Present' if tb.get('hasDrawnBy') else '\u2717 MISSING'} - {tb.get('drawnByValue', 'N/A')}\")\n        title_block_items.append(f\"- Approved By: {'\u2713 Present' if tb.get('hasApprovedBy') else '\u2717 MISSING'} - {tb.get('approvedByValue', 'N/A')}\")\n\n        # Drawing quality checklist\n        quality_items = []\n        quality_items.append(f\"- Views Labeled: {'\u2713 Yes' if dq.get('viewsLabeled') else '\u2717 No'} - {dq.get('viewsLabeledComment', '')}\")\n        quality_items.append(f\"- Dimensions Readable: {'\u2713 Yes' if dq.get('dimensionsReadable') else '\u2717 No'} - {dq.get('dimensionsComment', '')}\")\n        quality_items.append(f\"- Tolerances Present: {'\u2713 Yes' if dq.get('tolerancesPresent') else '\u2717 No'} - {dq.get('tolerancesComment', '')}\")\n        quality_items.append(f\"- Surface Finish Specified: {'\u2713 Yes' if dq.get('surfaceFinishSpecified') else '\u2717 No'} - {dq.get('surfaceFinishComment', '')}\")\n        quality_items.append(f\"- General Tolerance Block: {'\u2713 Yes' if dq.get('generalToleranceBlock') else '\u2717 No'} - {dq.get('generalToleranceComment', '')}\")\n        quality_items.append(f\"- Third Angle Projection Symbol: {'\u2713 Yes' if dq.get('thirdAngleProjection') else '\u2717 No'}\")\n        quality_items.append(f\"- Units Specified: {'\u2713 Yes' if dq.get('unitsSpecified') else '\u2717 No'} - {dq.get('unitsValue', 'N/A')}\")\n\n        # === BOM DATA ===\n        bom_section = \"\"\n        if bom_data.get('hasBOM'):\n            bom_items_text = []\n            for item in bom_data.get('bomItems', [])[:15]:\n                bom_items_text.append(f\"  - Item {item.get('itemNumber', '?')}: {item.get('partNumber', 'N/A')} - {item.get('description', 'N/A')} (Qty: {item.get('quantity', 1)})\")\n            bom_section = f\"\"\"\n### Bill of Materials (BOM):\n**BOM Present:** Yes (Location: {bom_data.get('bomLocation', 'N/A')})\n**Total Items:** {bom_data.get('totalItems', len(bom_data.get('bomItems', [])))}\n\n{chr(10).join(bom_items_text) if bom_items_text else \"No items extracted\"}\n\n**BOM Notes:** {bom_data.get('bomNotes', 'None')}\n\"\"\"\n        else:\n            bom_section = \"\"\"\n### Bill of Materials (BOM):\n**BOM Present:** No - This appears to be a part/detail drawing without a parts list.\n\"\"\"\n\n        # === MANUFACTURING NOTES ===\n        ht = mfg_notes.get('heatTreatment', {})\n        sf = mfg_notes.get('surfaceFinish', {})\n        pc = mfg_notes.get('platingOrCoating', {})\n        wn = mfg_notes.get('weldingNotes', {})\n        insp = mfg_notes.get('inspectionRequirements', {})\n\n        mfg_items = []\n        mfg_items.append(f\"- Heat Treatment: {'\u2713 ' + ht.get('specification', 'Specified') if ht.get('specified') else '\u2717 Not specified'}\")\n        mfg_items.append(f\"- Surface Finish: {'\u2713 ' + sf.get('generalFinish', 'Specified') if sf.get('specified') else '\u2717 Not specified'}\")\n        mfg_items.append(f\"- Plating/Coating: {'\u2713 ' + pc.get('type', 'Specified') if pc.get('specified') else '\u2717 Not specified'}\")\n        mfg_items.append(f\"- Welding: {'\u2713 ' + wn.get('weldSpec', 'Specified') if wn.get('specified') else '\u2717 Not specified'}\")\n        mfg_items.append(f\"- Inspection Requirements: {'\u2713 Specified' if insp.get('specified') else '\u2717 Not specified'}\")\n\n        general_notes = mfg_notes.get('generalNotes', [])\n        special_processes = mfg_notes.get('specialProcesses', [])\n        certifications = mfg_notes.get('certifications', [])\n\n        prompt = f\"\"\"You are a Quality Control engineer reviewing an engineering drawing inspection report. You have comprehensive data from AI vision analysis including:\n1. CAD-to-drawing feature comparison\n2. Drawing quality/completeness audit\n3. Bill of Materials extraction (if applicable)\n4. Manufacturing notes and special requirements\n\nYour job is to write a COMPREHENSIVE QC report covering ALL aspects of the drawing.\n\n---\n\n## PART 1: CAD FEATURE COMPARISON\n\n**Part Number:** {part_number}\n**Description:** {part_desc}\n**Material (from drawing):** {material}\n\n**CAD Model Requirements:** {summary.get('totalRequirements', 0)} features\n**Drawing Match Rate:** {summary.get('matchRate', 'N/A')}\n\n### Verified Features (Found in Drawing):\n{chr(10).join(found_items) if found_items else \"None\"}\n\n### Missing from Drawing (Required by CAD):\n{chr(10).join(missing_items) if missing_items else \"None\"}\n\n### Extra in Drawing (Not in CAD):\n{chr(10).join(extra_items) if extra_items else \"None\"}\n\n### Drawing Notes Observed:\n{chr(10).join(f\"- {note}\" for note in drawing_notes[:5]) if drawing_notes else \"None noted\"}\n\n---\n\n## PART 2: DRAWING QUALITY AUDIT\n\n### Title Block Completeness:\n{chr(10).join(title_block_items)}\n\n### Drawing Best Practices:\n{chr(10).join(quality_items)}\n\n### Overall Quality Score: {oa.get('completenessScore', 'N/A')}/10\n\n### Issues Identified:\n- Major: {', '.join(oa.get('majorIssues', [])) if oa.get('majorIssues') else 'None'}\n- Minor: {', '.join(oa.get('minorIssues', [])) if oa.get('minorIssues') else 'None'}\n\n---\n\n## PART 3: BILL OF MATERIALS\n{bom_section}\n\n---\n\n## PART 4: MANUFACTURING SPECIFICATIONS\n\n### Manufacturing Requirements:\n{chr(10).join(mfg_items)}\n\n### Special Processes:\n{chr(10).join(f\"- {sp.get('process', 'Unknown')}: {sp.get('specification', 'N/A')}\" for sp in special_processes) if special_processes else \"None specified\"}\n\n### General Manufacturing Notes:\n{chr(10).join(f\"- {note}\" for note in general_notes[:8]) if general_notes else \"None\"}\n\n### Inspection Requirements:\n{chr(10).join(f\"- {req}\" for req in insp.get('requirements', [])) if insp.get('specified') else \"None specified\"}\n\n### Certifications Required:\n{chr(10).join(f\"- {cert}\" for cert in certifications) if certifications else \"None specified\"}\n\n---\n\n## YOUR TASK\n\nWrite a professional, comprehensive QC inspection report in markdown format. Include:\n\n1. **Executive Summary** - Overall PASS/FAIL/REVIEW NEEDED verdict with key findings\n2. **Feature Verification Results** - CAD vs drawing comparison summary\n3. **Drawing Quality Assessment** - Title block, views, dimensions, tolerances\n4. **Bill of Materials Review** - If present, comment on completeness\n5. **Manufacturing Specifications** - Heat treat, finish, coatings, special processes\n6. **Issues & Action Items** - Specific problems and what needs to be fixed\n7. **Confidence Level** - HIGH/MEDIUM/LOW with justification\n\nBe specific and actionable. This report goes to manufacturing, engineering, and QC teams.\n\"\"\"\n\n        response = client.chat.completions.create(\n            model=\"gpt-4o-mini\",\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a senior QC engineer who writes clear, comprehensive inspection reports. You assess feature accuracy, drawing quality, and manufacturing specifications.\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ],\n            temperature=0.3,\n            max_tokens=2500\n        )\n\n        return response.choices[0].message.content\n\n    # Generate the report\n    print(\"=\"*50)\n    print(\"GENERATING QC REPORT WITH GPT-4o-mini...\")\n    print(\"=\"*50)\n\n    try:\n        qc_report = generate_qc_report(diff_result, evidence, sw_data, drawing_quality, bom_data, mfg_notes)\n\n        print(\"\\n\" + qc_report)\n\n        # Save report\n        report_out = os.path.join(OUTPUT_DIR, \"QCReport.md\")\n        with open(report_out, 'w') as f:\n            f.write(f\"# QC Inspection Report: {part_identity.partNumber}\\n\\n\")\n            f.write(f\"**Generated:** {datetime.now().isoformat()}\\n\\n\")\n            f.write(f\"**Drawing:** {DRAWING_PDF_PATH}\\n\\n\")\n            f.write(\"---\\n\\n\")\n            f.write(qc_report)\n\n        print(f\"\\n{'='*50}\")\n        print(f\"Saved: {report_out}\")\n\n        # Also display in Colab with formatting\n        from IPython.display import display, Markdown\n        display(Markdown(qc_report))\n\n    except Exception as e:\n        print(f\"Error generating report: {e}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}