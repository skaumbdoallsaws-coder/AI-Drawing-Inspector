{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Test Full Pipeline: End-to-End (M11)\n\nThis notebook runs the complete YOLO-OBB pipeline end-to-end:\n\n```\nimage -> detect -> crop -> rotate+OCR -> parse -> normalize -> validate -> expand -> match -> score\n```\n\nUses `YOLOPipeline` which orchestrates all 10 stages in a single `run()` call.\n\n**Runtime requirement:** GPU with at least 8 GB VRAM (T4 or better).\n\n**Required uploads (via file explorer dialog):**\n- Sample page image (PNG/JPG)\n- SolidWorks JSON export (single `.json` or `.zip` library)\n- HuggingFace token for LightOnOCR-2 (entered via prompt)"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 1: Install all dependencies + clone and install ai_inspector package\n# NOTE: Set your runtime to GPU before running (Runtime > Change runtime type > T4 or better)\n%pip install ultralytics transformers torch pillow accelerate --quiet\n\n# Clone the repo (or pull latest if already cloned)\n!git clone https://github.com/skaumbdoallsaws-coder/AI-Drawing-Inspector.git /content/AI-Drawing-Inspector 2>/dev/null || \\\n    (cd /content/AI-Drawing-Inspector && git pull)\n\n# Install ai_inspector as an editable package so relative imports work\n%pip install -e /content/AI-Drawing-Inspector --quiet\n\nprint('Dependencies installed.')\nprint('ai_inspector package installed.')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 2: Upload files + set paths (no Drive mount required)\nimport os\nimport re\nimport json\nimport zipfile\nfrom pathlib import Path\n\n# ---- Colab file-upload helper ----\ntry:\n    from google.colab import userdata, files  # type: ignore\n    IN_COLAB = True\nexcept Exception:\n    IN_COLAB = False\n    userdata = None\n    files = None\n\nUPLOAD_DIR = '/content/uploads'\nos.makedirs(UPLOAD_DIR, exist_ok=True)\n\n# ---- HuggingFace token ----\nHF_TOKEN = None\nif IN_COLAB and userdata is not None:\n    try:\n        HF_TOKEN = userdata.get('HF_TOKEN')\n    except Exception:\n        HF_TOKEN = None\n\nif not HF_TOKEN:\n    try:\n        from getpass import getpass\n        entered = getpass('Enter HF_TOKEN (leave blank to skip): ').strip()\n        HF_TOKEN = entered or None\n    except Exception:\n        HF_TOKEN = None\n\nif HF_TOKEN:\n    os.environ['HF_TOKEN'] = HF_TOKEN\n    print(f'HF_TOKEN set (length={len(HF_TOKEN)})')\nelse:\n    print('WARNING: HF_TOKEN not set. LightOnOCR model loading will fail.')\n\n# ---- Upload drawing image ----\nprint('\\n--- Upload your drawing image (PNG/JPG) ---')\nSAMPLE_IMAGE = ''\nif IN_COLAB and files is not None:\n    uploaded = files.upload()\n    for fname, data in uploaded.items():\n        dest = os.path.join(UPLOAD_DIR, fname)\n        with open(dest, 'wb') as f:\n            f.write(data)\n        if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.tif', '.tiff', '.bmp')):\n            SAMPLE_IMAGE = dest\n            print(f'Drawing image saved: {dest}')\nelse:\n    # Local fallback: enter path manually\n    SAMPLE_IMAGE = input('Enter local path to drawing image: ').strip()\n\nif not SAMPLE_IMAGE or not os.path.exists(SAMPLE_IMAGE):\n    raise FileNotFoundError(\n        f'No valid drawing image found. Got: \"{SAMPLE_IMAGE}\"\\n'\n        'Re-run this cell and upload a PNG/JPG drawing page.'\n    )\n\n# ---- Upload SW JSON or ZIP ----\nprint('\\n--- Upload SolidWorks data (.json or .zip) ---')\nprint('(You may upload a single JSON file or a zip library. Press Cancel/skip if none.)')\nSW_JSON_PATH = ''\nSW_ZIP_PATH = ''\nif IN_COLAB and files is not None:\n    try:\n        uploaded_sw = files.upload()\n        for fname, data in uploaded_sw.items():\n            dest = os.path.join(UPLOAD_DIR, fname)\n            with open(dest, 'wb') as f:\n                f.write(data)\n            if fname.lower().endswith('.json'):\n                SW_JSON_PATH = dest\n                print(f'SW JSON saved: {dest}')\n            elif fname.lower().endswith('.zip'):\n                SW_ZIP_PATH = dest\n                print(f'SW ZIP saved: {dest}')\n    except Exception:\n        print('SW upload skipped. Pipeline will run without SW comparison data.')\nelse:\n    sw_input = input('Enter local path to SW JSON or ZIP (blank to skip): ').strip()\n    if sw_input:\n        if sw_input.lower().endswith('.zip'):\n            SW_ZIP_PATH = sw_input\n        else:\n            SW_JSON_PATH = sw_input\n\n# ---- Paths ----\nMODEL_PATH = 'hf://shadrack20s/ai-inspector-callout-detection/callout_v2_yolo11s-obb_best.pt'\nOUTPUT_DIR = '/content/debug/pipeline_run'\nTITLE_BLOCK_TEXT = 'UNLESS OTHERWISE SPECIFIED DIMENSIONS ARE IN INCHES'\nos.makedirs(OUTPUT_DIR, exist_ok=True)\n\n\n# ---- Auto-resolve SW JSON from ZIP if needed ----\ndef _normalize(s: str) -> str:\n    return re.sub(r'[-\\s_]', '', str(s or '')).lower()\n\n\ndef _extract_candidates(filename: str):\n    stem = Path(filename).stem\n    stem = re.sub(r\"\\s*\\(\\d+\\)$\", '', stem)\n    base = stem\n    candidates = [base, base.replace('-', '')]\n    for tok in [' Paint', '_Paint', '-Paint', ' PAINT', '_PAINT', '-PAINT']:\n        if base.endswith(tok):\n            b2 = base[: -len(tok)]\n            candidates.extend([b2, b2.replace('-', '')])\n    m = re.match(r'^(.+?)[-_](\\d{1,2})$', base)\n    if m:\n        candidates.extend([m.group(1), m.group(1).replace('-', '')])\n    m = re.match(r'^(.+?)[-_]?REV[-_]?[A-Z0-9]*$', base, re.IGNORECASE)\n    if m:\n        candidates.extend([m.group(1), m.group(1).replace('-', '')])\n    peeled = base.replace('-', '')\n    while len(peeled) > 5:\n        candidates.append(peeled)\n        peeled = peeled[:-1]\n    out, seen = [], set()\n    for c in candidates:\n        if c and c not in seen:\n            seen.add(c)\n            out.append(c)\n    return out\n\n\ndef _resolve_sw_json_from_zip(sample_image_path, zip_path, extract_dir='/content/sw_json_library'):\n    if not os.path.exists(zip_path):\n        return None, 'zip_not_found'\n    os.makedirs(extract_dir, exist_ok=True)\n    idx_path = os.path.join(extract_dir, '_batch_index.json')\n    with zipfile.ZipFile(zip_path, 'r') as zf:\n        names = set(zf.namelist())\n        if '_batch_index.json' in names and not os.path.exists(idx_path):\n            zf.extract('_batch_index.json', extract_dir)\n        if not os.path.exists(idx_path):\n            candidates = _extract_candidates(os.path.basename(sample_image_path))\n            for c in candidates:\n                direct = f'{c}.json'\n                if direct in names:\n                    zf.extract(direct, extract_dir)\n                    return os.path.join(extract_dir, direct), 'zip_direct_filename'\n            return None, 'index_missing'\n    # Use utf-8-sig to silently strip the BOM that Windows/.NET tools\n    # (e.g. the SolidWorks extractor) prepend to JSON files.\n    with open(idx_path, 'r', encoding='utf-8-sig') as f:\n        idx = json.load(f)\n    records = idx.get('records', [])\n    if not records:\n        return None, 'index_no_records'\n    candidates = _extract_candidates(os.path.basename(sample_image_path))\n    norm_cands = [_normalize(c) for c in candidates]\n    by_pn, by_json_stem = {}, {}\n    for r in records:\n        pn = str(r.get('partNumber', '') or '')\n        jf = str(r.get('jsonFileName', '') or '')\n        stem = Path(jf).stem if jf else ''\n        if pn:\n            by_pn[_normalize(pn)] = jf\n        if stem:\n            by_json_stem[_normalize(stem)] = jf\n    chosen, reason = None, None\n    for c in norm_cands:\n        if c in by_pn:\n            chosen, reason = by_pn[c], f'index_partNumber:{c}'\n            break\n    if not chosen:\n        for c in norm_cands:\n            if c in by_json_stem:\n                chosen, reason = by_json_stem[c], f'index_json_stem:{c}'\n                break\n    if not chosen:\n        return None, f'no_match_for_candidates:{candidates[:5]}'\n    out_path = os.path.join(extract_dir, chosen)\n    if not os.path.exists(out_path):\n        with zipfile.ZipFile(zip_path, 'r') as zf:\n            zf.extract(chosen, extract_dir)\n    if os.path.exists(out_path):\n        return out_path, reason\n    return None, 'extract_failed'\n\n\n# Auto-resolve SW JSON from ZIP if we got a ZIP but no direct JSON\nif not SW_JSON_PATH and SW_ZIP_PATH:\n    resolved_sw, why = _resolve_sw_json_from_zip(SAMPLE_IMAGE, SW_ZIP_PATH)\n    if resolved_sw:\n        SW_JSON_PATH = resolved_sw\n        print(f'Auto-matched SW JSON: {SW_JSON_PATH} ({why})')\n    else:\n        print(f'WARNING: Could not auto-match SW JSON from ZIP ({why}).')\n\nprint(f'\\nModel:       {MODEL_PATH}')\nprint(f'Image:       {SAMPLE_IMAGE}  exists={os.path.exists(SAMPLE_IMAGE)}')\nprint(f'SW JSON:     {SW_JSON_PATH or \"<none>\"}  exists={os.path.exists(SW_JSON_PATH) if SW_JSON_PATH else False}')\nprint(f'Output dir:  {OUTPUT_DIR}')",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3: Import YOLOPipeline\n",
    "from ai_inspector.pipeline.yolo_pipeline import YOLOPipeline, PipelineResult\n",
    "\n",
    "print('YOLOPipeline imported successfully.')\n",
    "print(f'PipelineResult fields: {[f.name for f in PipelineResult.__dataclass_fields__.values()]}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 4: Create and load pipeline (show GPU memory usage)\n",
    "import torch\n",
    "\n",
    "def gpu_mem():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        return f'{allocated:.2f} GB allocated / {reserved:.2f} GB reserved / {total:.1f} GB total'\n",
    "    return 'No CUDA'\n",
    "\n",
    "print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')\n",
    "print(f'Before load: {gpu_mem()}')\n",
    "\n",
    "pipeline = YOLOPipeline(\n",
    "    model_path=MODEL_PATH,\n",
    "    hf_token=HF_TOKEN,\n",
    "    confidence_threshold=0.25,\n",
    "    device='cuda',\n",
    ")\n",
    "\n",
    "pipeline.load()\n",
    "print(f'Pipeline loaded: {pipeline.is_loaded}')\n",
    "print(f'After load:  {gpu_mem()}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Run pipeline on a test page\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result = pipeline.run(\n",
    "    image_path=SAMPLE_IMAGE,\n",
    "    sw_json_path=SW_JSON_PATH,\n",
    "    title_block_text=TITLE_BLOCK_TEXT,\n",
    "    page_id='test_page_0',\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_crops=True,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f'Pipeline completed in {elapsed:.1f}s')\n",
    "print(f'Packets: {len(result.packets)}')\n",
    "print(f'Match results: {len(result.match_results)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 6: Display results: scores, expansion summary, validation stats\n",
    "import json\n",
    "\n",
    "print('=== SCORES ===')\n",
    "for key, val in result.scores.items():\n",
    "    print(f'  {key:25s}: {val}')\n",
    "\n",
    "print('\\n=== EXPANSION SUMMARY ===')\n",
    "print(json.dumps(result.expansion_summary, indent=2))\n",
    "\n",
    "print('\\n=== VALIDATION STATS ===')\n",
    "print(json.dumps(result.validation_stats, indent=2))\n",
    "\n",
    "print('\\n=== PACKET SUMMARY ===')\n",
    "print(json.dumps(result.packet_summary, indent=2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: Display match results table\n",
    "from ai_inspector.comparison.matcher import MatchStatus\n",
    "\n",
    "print(f'{\"#\":>3s} {\"Status\":15s} {\"Type\":18s} {\"Delta\":>10s} {\"Notes\"}')\n",
    "print('=' * 90)\n",
    "\n",
    "for i, r in enumerate(result.match_results):\n",
    "    # Determine type from whichever side is present\n",
    "    callout_type = ''\n",
    "    if r.drawing_callout:\n",
    "        callout_type = r.drawing_callout.get('calloutType', '')\n",
    "    elif r.sw_feature:\n",
    "        callout_type = r.sw_feature.feature_type\n",
    "\n",
    "    delta_str = f'{r.delta:+.4f}' if r.delta is not None else 'N/A'\n",
    "\n",
    "    # Color coding via emoji-free markers\n",
    "    status_marker = {\n",
    "        MatchStatus.MATCHED: '[OK]',\n",
    "        MatchStatus.MISSING: '[MISS]',\n",
    "        MatchStatus.EXTRA: '[EXTRA]',\n",
    "        MatchStatus.TOLERANCE_FAIL: '[TOL]',\n",
    "        MatchStatus.SKIPPED: '[SKIP]',\n",
    "    }.get(r.status, '[?]')\n",
    "\n",
    "    print(f'{i:3d} {status_marker + \" \" + r.status.value:15s} '\n",
    "          f'{callout_type:18s} {delta_str:>10s} {r.notes[:50]}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 8: Display packet provenance for first 5 detections\n",
    "from ai_inspector.schemas.callout_packet import packet_to_dict\n",
    "\n",
    "print('=== Packet Provenance (first 5) ===')\n",
    "print()\n",
    "\n",
    "for i, pkt in enumerate(result.packets[:5]):\n",
    "    print(f'--- Packet {i}: {pkt.det_id} ---')\n",
    "\n",
    "    # Detection\n",
    "    if pkt.detection:\n",
    "        print(f'  Detection: class={pkt.detection.class_name}, '\n",
    "              f'conf={pkt.detection.confidence:.3f}')\n",
    "\n",
    "    # Crop\n",
    "    if pkt.crop:\n",
    "        meta = pkt.crop.meta\n",
    "        print(f'  Crop: {meta.get(\"crop_w\", \"?\")}x{meta.get(\"crop_h\", \"?\")}px, '\n",
    "              f'angle={meta.get(\"rotation_angle\", 0):.1f}deg')\n",
    "\n",
    "    # Rotation\n",
    "    if pkt.rotation:\n",
    "        print(f'  Rotation: {pkt.rotation.rotation_used}deg, '\n",
    "              f'quality={pkt.rotation.quality_score:.2f}')\n",
    "\n",
    "    # Reader\n",
    "    if pkt.reader:\n",
    "        print(f'  Reader: type={pkt.reader.callout_type}, '\n",
    "              f'source={pkt.reader.source}, '\n",
    "              f'ocr_conf={pkt.reader.ocr_confidence:.2f}')\n",
    "        print(f'  Raw: \"{pkt.reader.raw[:60]}\"')\n",
    "        parsed_keys = [k for k in pkt.reader.parsed.keys() if not k.startswith('_')]\n",
    "        print(f'  Parsed fields: {parsed_keys}')\n",
    "\n",
    "    # Normalization\n",
    "    if pkt.normalized:\n",
    "        method = pkt.normalized.get('_normalization_method', '?')\n",
    "        units = pkt.normalized.get('_detected_units', '?')\n",
    "        print(f'  Normalization: method={method}, detected_units={units}')\n",
    "\n",
    "    # Validation\n",
    "    print(f'  Validated: {pkt.validated}'\n",
    "          + (f', error=\"{pkt.validation_error}\"' if pkt.validation_error else ''))\n",
    "\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 9: Save all artifacts to output dir\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out = Path(OUTPUT_DIR)\n",
    "print(f'Artifacts saved to: {OUTPUT_DIR}/')\n",
    "print()\n",
    "\n",
    "# List saved files\n",
    "for f in sorted(out.rglob('*')):\n",
    "    if f.is_file():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f'  {f.relative_to(out)}  ({size_kb:.1f} KB)')\n",
    "\n",
    "# Save the full result dict as well\n",
    "result_dict = result.to_dict()\n",
    "summary_path = out / 'pipeline_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(result_dict, f, indent=2, ensure_ascii=False)\n",
    "print(f'\\nPipeline summary saved to: {summary_path}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 10: Unload pipeline, show memory freed\n",
    "import torch\n",
    "\n",
    "def gpu_mem():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        return f'{allocated:.2f} GB allocated / {reserved:.2f} GB reserved / {total:.1f} GB total'\n",
    "    return 'No CUDA'\n",
    "\n",
    "print(f'Before unload: {gpu_mem()}')\n",
    "\n",
    "pipeline.unload()\n",
    "\n",
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'After unload:  {gpu_mem()}')\n",
    "print(f'Pipeline loaded: {pipeline.is_loaded}')\n",
    "print('\\nDone. Pipeline unloaded and memory freed.')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}