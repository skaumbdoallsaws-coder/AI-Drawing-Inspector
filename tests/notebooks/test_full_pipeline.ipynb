{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "A100"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Full Pipeline: End-to-End (M11)\n",
    "\n",
    "This notebook runs the complete YOLO-OBB pipeline end-to-end:\n",
    "\n",
    "```\n",
    "image -> detect -> crop -> rotate+OCR -> parse -> normalize -> validate -> expand -> match -> score\n",
    "```\n",
    "\n",
    "Uses `YOLOPipeline` which orchestrates all 10 stages in a single `run()` call.\n",
    "\n",
    "**Runtime requirement:** GPU with at least 8 GB VRAM (A100 preferred).\n",
    "\n",
    "**Required files on Google Drive:**\n",
    "- YOLO-OBB model weights (`best.pt`)\n",
    "- Sample page image (PNG/JPG)\n",
    "- SolidWorks JSON export\n",
    "- HuggingFace token for LightOnOCR-2"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 1: Install all dependencies\n",
    "# NOTE: Set your runtime to GPU before running (Runtime > Change runtime type > A100)\n",
    "%pip install ultralytics transformers torch pillow accelerate --quiet\n",
    "\n",
    "# Clone the repo\n",
    "!git clone https://github.com/skaumbdoallsaws-coder/AI-Drawing-Inspector.git /content/AI-Drawing-Inspector 2>/dev/null || \\\n",
    "    (cd /content/AI-Drawing-Inspector && git pull)\n",
    "\n",
    "print('Dependencies installed.')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 2: Mount Drive, set all paths + auto-resolve SW JSON from ZIP\n",
    "import sys\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Add repo to Python path\n",
    "sys.path.insert(0, '/content/AI-Drawing-Inspector')\n",
    "\n",
    "# ---- Optional: Colab helpers ----\n",
    "try:\n",
    "    from google.colab import drive, userdata, files  # type: ignore\n",
    "    IN_COLAB = True\n",
    "except Exception:\n",
    "    IN_COLAB = False\n",
    "    userdata = None\n",
    "    files = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    try:\n",
    "        drive.mount('/content/drive')\n",
    "        print('Google Drive mounted.')\n",
    "    except Exception:\n",
    "        print('Google Drive mount skipped. Proceeding with local files/upload.')\n",
    "else:\n",
    "    print('Not running in Colab. Using local filesystem.')\n",
    "\n",
    "# ---- HuggingFace token ----\n",
    "HF_TOKEN = None\n",
    "if IN_COLAB and userdata is not None:\n",
    "    try:\n",
    "        HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "    except Exception:\n",
    "        HF_TOKEN = None\n",
    "\n",
    "if not HF_TOKEN and IN_COLAB:\n",
    "    try:\n",
    "        from getpass import getpass\n",
    "        entered = getpass('Enter HF_TOKEN (leave blank to skip): ').strip()\n",
    "        HF_TOKEN = entered or None\n",
    "    except Exception:\n",
    "        HF_TOKEN = None\n",
    "\n",
    "if HF_TOKEN:\n",
    "    os.environ['HF_TOKEN'] = HF_TOKEN\n",
    "    print(f'HF_TOKEN set (length={len(HF_TOKEN)})')\n",
    "else:\n",
    "    print('WARNING: HF_TOKEN not set. LightOnOCR model loading will fail until token is provided.')\n",
    "\n",
    "# ---- Paths ----\n",
    "MODEL_PATH = 'hf://shadrack20s/ai-inspector-callout-detection/callout_v2_yolo11s-obb_best.pt'\n",
    "\n",
    "# Inputs (set these if you know exact files)\n",
    "SAMPLE_IMAGE = '/content/drive/MyDrive/ai_inspector_data/sample_pages/test_page.png'\n",
    "SW_JSON_PATH = '/content/drive/MyDrive/ai_inspector_data/sw_json/test_part.json'\n",
    "SW_ZIP_PATH = '/content/drive/MyDrive/ai_inspector_data/sw_json_library.zip'\n",
    "OUTPUT_DIR = '/content/debug/pipeline_run'\n",
    "TITLE_BLOCK_TEXT = 'UNLESS OTHERWISE SPECIFIED DIMENSIONS ARE IN INCHES'\n",
    "\n",
    "# Local fallbacks\n",
    "if not os.path.exists(SAMPLE_IMAGE):\n",
    "    for c in ['/content/test_page.png', '/content/00595601_04.png']:\n",
    "        if os.path.exists(c):\n",
    "            SAMPLE_IMAGE = c\n",
    "            break\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "def _normalize(s: str) -> str:\n",
    "    return re.sub(r'[-\\s_]', '', str(s or '')).lower()\n",
    "\n",
    "\n",
    "def _extract_candidates(filename: str):\n",
    "    stem = Path(filename).stem\n",
    "    stem = re.sub(r\"\\s*\\(\\d+\\)$\", '', stem)\n",
    "    base = stem\n",
    "\n",
    "    candidates = [base, base.replace('-', '')]\n",
    "\n",
    "    # Trim common suffix tokens\n",
    "    for tok in [' Paint', '_Paint', '-Paint', ' PAINT', '_PAINT', '-PAINT']:\n",
    "        if base.endswith(tok):\n",
    "            b2 = base[: -len(tok)]\n",
    "            candidates.extend([b2, b2.replace('-', '')])\n",
    "\n",
    "    # Revision style suffixes\n",
    "    m = re.match(r'^(.+?)[-_](\\d{1,2})$', base)\n",
    "    if m:\n",
    "        candidates.extend([m.group(1), m.group(1).replace('-', '')])\n",
    "\n",
    "    # REV markers\n",
    "    m = re.match(r'^(.+?)[-_]?REV[-_]?[A-Z0-9]*$', base, re.IGNORECASE)\n",
    "    if m:\n",
    "        candidates.extend([m.group(1), m.group(1).replace('-', '')])\n",
    "\n",
    "    # Progressive peel for concatenated revs\n",
    "    peeled = base.replace('-', '')\n",
    "    while len(peeled) > 5:\n",
    "        candidates.append(peeled)\n",
    "        peeled = peeled[:-1]\n",
    "\n",
    "    # unique preserve order\n",
    "    out, seen = [], set()\n",
    "    for c in candidates:\n",
    "        if c and c not in seen:\n",
    "            seen.add(c)\n",
    "            out.append(c)\n",
    "    return out\n",
    "\n",
    "\n",
    "def _resolve_sw_json_from_zip(sample_image_path: str, zip_path: str, extract_dir: str = '/content/sw_json_library'):\n",
    "    if not os.path.exists(zip_path):\n",
    "        return None, 'zip_not_found'\n",
    "\n",
    "    os.makedirs(extract_dir, exist_ok=True)\n",
    "    idx_path = os.path.join(extract_dir, '_batch_index.json')\n",
    "\n",
    "    # Extract index and candidate records first (faster than full extract)\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "        names = set(zf.namelist())\n",
    "        if '_batch_index.json' in names and not os.path.exists(idx_path):\n",
    "            zf.extract('_batch_index.json', extract_dir)\n",
    "\n",
    "        if not os.path.exists(idx_path):\n",
    "            # fallback: no index, try by filename directly if exact JSON exists in zip\n",
    "            candidates = _extract_candidates(os.path.basename(sample_image_path))\n",
    "            for c in candidates:\n",
    "                direct = f'{c}.json'\n",
    "                if direct in names:\n",
    "                    zf.extract(direct, extract_dir)\n",
    "                    return os.path.join(extract_dir, direct), 'zip_direct_filename'\n",
    "            return None, 'index_missing'\n",
    "\n",
    "    with open(idx_path, 'r', encoding='utf-8') as f:\n",
    "        idx = json.load(f)\n",
    "\n",
    "    records = idx.get('records', [])\n",
    "    if not records:\n",
    "        return None, 'index_no_records'\n",
    "\n",
    "    candidates = _extract_candidates(os.path.basename(sample_image_path))\n",
    "    norm_cands = [_normalize(c) for c in candidates]\n",
    "\n",
    "    # Build lookup maps\n",
    "    by_pn = {}\n",
    "    by_json_stem = {}\n",
    "    for r in records:\n",
    "        pn = str(r.get('partNumber', '') or '')\n",
    "        jf = str(r.get('jsonFileName', '') or '')\n",
    "        stem = Path(jf).stem if jf else ''\n",
    "        if pn:\n",
    "            by_pn[_normalize(pn)] = jf\n",
    "        if stem:\n",
    "            by_json_stem[_normalize(stem)] = jf\n",
    "\n",
    "    chosen = None\n",
    "    reason = None\n",
    "\n",
    "    for c in norm_cands:\n",
    "        if c in by_pn:\n",
    "            chosen = by_pn[c]\n",
    "            reason = f'index_partNumber:{c}'\n",
    "            break\n",
    "\n",
    "    if not chosen:\n",
    "        for c in norm_cands:\n",
    "            if c in by_json_stem:\n",
    "                chosen = by_json_stem[c]\n",
    "                reason = f'index_json_stem:{c}'\n",
    "                break\n",
    "\n",
    "    if not chosen:\n",
    "        return None, f'no_match_for_candidates:{candidates[:5]}'\n",
    "\n",
    "    out_path = os.path.join(extract_dir, chosen)\n",
    "    if not os.path.exists(out_path):\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zf:\n",
    "            zf.extract(chosen, extract_dir)\n",
    "\n",
    "    if os.path.exists(out_path):\n",
    "        return out_path, reason\n",
    "    return None, 'extract_failed'\n",
    "\n",
    "\n",
    "# Auto-resolve SW_JSON_PATH if missing\n",
    "if not os.path.exists(SW_JSON_PATH):\n",
    "    resolved_sw, why = _resolve_sw_json_from_zip(SAMPLE_IMAGE, SW_ZIP_PATH)\n",
    "    if resolved_sw:\n",
    "        SW_JSON_PATH = resolved_sw\n",
    "        print(f'Auto-matched SW JSON: {SW_JSON_PATH} ({why})')\n",
    "    else:\n",
    "        SW_JSON_PATH = ''\n",
    "        print(f'WARNING: Could not auto-match SW JSON ({why}). Pipeline will run without SW comparison data.')\n",
    "\n",
    "print(f'Model:       {MODEL_PATH}')\n",
    "print(f'Image:       {SAMPLE_IMAGE}  exists={os.path.exists(SAMPLE_IMAGE)}')\n",
    "print(f'SW JSON:     {SW_JSON_PATH or \"<none>\"}  exists={os.path.exists(SW_JSON_PATH) if SW_JSON_PATH else False}')\n",
    "print(f'SW ZIP:      {SW_ZIP_PATH}  exists={os.path.exists(SW_ZIP_PATH)}')\n",
    "print(f'Output dir:  {OUTPUT_DIR}')\n",
    "\n",
    "if not os.path.exists(SAMPLE_IMAGE):\n",
    "    raise FileNotFoundError(\n",
    "        f'SAMPLE_IMAGE not found: {SAMPLE_IMAGE}\\n'\n",
    "        'Provide a valid image path in Cell 2 before running the pipeline.'\n",
    "    )\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 3: Import YOLOPipeline\n",
    "from ai_inspector.pipeline.yolo_pipeline import YOLOPipeline, PipelineResult\n",
    "\n",
    "print('YOLOPipeline imported successfully.')\n",
    "print(f'PipelineResult fields: {[f.name for f in PipelineResult.__dataclass_fields__.values()]}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 4: Create and load pipeline (show GPU memory usage)\n",
    "import torch\n",
    "\n",
    "def gpu_mem():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        return f'{allocated:.2f} GB allocated / {reserved:.2f} GB reserved / {total:.1f} GB total'\n",
    "    return 'No CUDA'\n",
    "\n",
    "print(f'GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"N/A\"}')\n",
    "print(f'Before load: {gpu_mem()}')\n",
    "\n",
    "pipeline = YOLOPipeline(\n",
    "    model_path=MODEL_PATH,\n",
    "    hf_token=HF_TOKEN,\n",
    "    confidence_threshold=0.25,\n",
    "    device='cuda',\n",
    ")\n",
    "\n",
    "pipeline.load()\n",
    "print(f'Pipeline loaded: {pipeline.is_loaded}')\n",
    "print(f'After load:  {gpu_mem()}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 5: Run pipeline on a test page\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "result = pipeline.run(\n",
    "    image_path=SAMPLE_IMAGE,\n",
    "    sw_json_path=SW_JSON_PATH,\n",
    "    title_block_text=TITLE_BLOCK_TEXT,\n",
    "    page_id='test_page_0',\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    save_crops=True,\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f'Pipeline completed in {elapsed:.1f}s')\n",
    "print(f'Packets: {len(result.packets)}')\n",
    "print(f'Match results: {len(result.match_results)}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 6: Display results: scores, expansion summary, validation stats\n",
    "import json\n",
    "\n",
    "print('=== SCORES ===')\n",
    "for key, val in result.scores.items():\n",
    "    print(f'  {key:25s}: {val}')\n",
    "\n",
    "print('\\n=== EXPANSION SUMMARY ===')\n",
    "print(json.dumps(result.expansion_summary, indent=2))\n",
    "\n",
    "print('\\n=== VALIDATION STATS ===')\n",
    "print(json.dumps(result.validation_stats, indent=2))\n",
    "\n",
    "print('\\n=== PACKET SUMMARY ===')\n",
    "print(json.dumps(result.packet_summary, indent=2))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: Display match results table\n",
    "from ai_inspector.comparison.matcher import MatchStatus\n",
    "\n",
    "print(f'{\"#\":>3s} {\"Status\":15s} {\"Type\":18s} {\"Delta\":>10s} {\"Notes\"}')\n",
    "print('=' * 90)\n",
    "\n",
    "for i, r in enumerate(result.match_results):\n",
    "    # Determine type from whichever side is present\n",
    "    callout_type = ''\n",
    "    if r.drawing_callout:\n",
    "        callout_type = r.drawing_callout.get('calloutType', '')\n",
    "    elif r.sw_feature:\n",
    "        callout_type = r.sw_feature.feature_type\n",
    "\n",
    "    delta_str = f'{r.delta:+.4f}' if r.delta is not None else 'N/A'\n",
    "\n",
    "    # Color coding via emoji-free markers\n",
    "    status_marker = {\n",
    "        MatchStatus.MATCHED: '[OK]',\n",
    "        MatchStatus.MISSING: '[MISS]',\n",
    "        MatchStatus.EXTRA: '[EXTRA]',\n",
    "        MatchStatus.TOLERANCE_FAIL: '[TOL]',\n",
    "        MatchStatus.SKIPPED: '[SKIP]',\n",
    "    }.get(r.status, '[?]')\n",
    "\n",
    "    print(f'{i:3d} {status_marker + \" \" + r.status.value:15s} '\n",
    "          f'{callout_type:18s} {delta_str:>10s} {r.notes[:50]}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 8: Display packet provenance for first 5 detections\n",
    "from ai_inspector.schemas.callout_packet import packet_to_dict\n",
    "\n",
    "print('=== Packet Provenance (first 5) ===')\n",
    "print()\n",
    "\n",
    "for i, pkt in enumerate(result.packets[:5]):\n",
    "    print(f'--- Packet {i}: {pkt.det_id} ---')\n",
    "\n",
    "    # Detection\n",
    "    if pkt.detection:\n",
    "        print(f'  Detection: class={pkt.detection.class_name}, '\n",
    "              f'conf={pkt.detection.confidence:.3f}')\n",
    "\n",
    "    # Crop\n",
    "    if pkt.crop:\n",
    "        meta = pkt.crop.meta\n",
    "        print(f'  Crop: {meta.get(\"crop_w\", \"?\")}x{meta.get(\"crop_h\", \"?\")}px, '\n",
    "              f'angle={meta.get(\"rotation_angle\", 0):.1f}deg')\n",
    "\n",
    "    # Rotation\n",
    "    if pkt.rotation:\n",
    "        print(f'  Rotation: {pkt.rotation.rotation_used}deg, '\n",
    "              f'quality={pkt.rotation.quality_score:.2f}')\n",
    "\n",
    "    # Reader\n",
    "    if pkt.reader:\n",
    "        print(f'  Reader: type={pkt.reader.callout_type}, '\n",
    "              f'source={pkt.reader.source}, '\n",
    "              f'ocr_conf={pkt.reader.ocr_confidence:.2f}')\n",
    "        print(f'  Raw: \"{pkt.reader.raw[:60]}\"')\n",
    "        parsed_keys = [k for k in pkt.reader.parsed.keys() if not k.startswith('_')]\n",
    "        print(f'  Parsed fields: {parsed_keys}')\n",
    "\n",
    "    # Normalization\n",
    "    if pkt.normalized:\n",
    "        method = pkt.normalized.get('_normalization_method', '?')\n",
    "        units = pkt.normalized.get('_detected_units', '?')\n",
    "        print(f'  Normalization: method={method}, detected_units={units}')\n",
    "\n",
    "    # Validation\n",
    "    print(f'  Validated: {pkt.validated}'\n",
    "          + (f', error=\"{pkt.validation_error}\"' if pkt.validation_error else ''))\n",
    "\n",
    "    print()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 9: Save all artifacts to output dir\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "out = Path(OUTPUT_DIR)\n",
    "print(f'Artifacts saved to: {OUTPUT_DIR}/')\n",
    "print()\n",
    "\n",
    "# List saved files\n",
    "for f in sorted(out.rglob('*')):\n",
    "    if f.is_file():\n",
    "        size_kb = f.stat().st_size / 1024\n",
    "        print(f'  {f.relative_to(out)}  ({size_kb:.1f} KB)')\n",
    "\n",
    "# Save the full result dict as well\n",
    "result_dict = result.to_dict()\n",
    "summary_path = out / 'pipeline_summary.json'\n",
    "with open(summary_path, 'w') as f:\n",
    "    json.dump(result_dict, f, indent=2, ensure_ascii=False)\n",
    "print(f'\\nPipeline summary saved to: {summary_path}')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 10: Unload pipeline, show memory freed\n",
    "import torch\n",
    "\n",
    "def gpu_mem():\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1e9\n",
    "        reserved = torch.cuda.memory_reserved() / 1e9\n",
    "        total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        return f'{allocated:.2f} GB allocated / {reserved:.2f} GB reserved / {total:.1f} GB total'\n",
    "    return 'No CUDA'\n",
    "\n",
    "print(f'Before unload: {gpu_mem()}')\n",
    "\n",
    "pipeline.unload()\n",
    "\n",
    "# Force garbage collection\n",
    "import gc\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(f'After unload:  {gpu_mem()}')\n",
    "print(f'Pipeline loaded: {pipeline.is_loaded}')\n",
    "print('\\nDone. Pipeline unloaded and memory freed.')"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
