{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial Drawing Inspection\n",
    "**Claude Vision + GPT-4o Report Generator**\n",
    "\n",
    "Pipeline:\n",
    "1. Match drawing to its inspection profile from the parts library\n",
    "2. Claude Vision analyzes the drawing against the expected feature profile\n",
    "3. GPT-4o generates a QC report from Claude's findings\n",
    "\n",
    "No GPU required — runs on API calls only.\n",
    "\n",
    "**Required:** `.env` file with `ANTHROPIC_API_KEY` and `OPENAI_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 1: Setup\n",
    "import anthropic\n",
    "import base64\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\", \"\").strip()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\").strip()\n",
    "\n",
    "assert ANTHROPIC_API_KEY, \"Missing ANTHROPIC_API_KEY in .env\"\n",
    "assert OPENAI_API_KEY, \"Missing OPENAI_API_KEY in .env\"\n",
    "\n",
    "print(f\"Anthropic key: ...{ANTHROPIC_API_KEY[-8:]}\")\n",
    "print(f\"OpenAI key:    ...{OPENAI_API_KEY[-8:]}\")\n",
    "print(\"Setup complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Configuration\n\nEdit the cell below for each inspection run:\n- **`PART_NUMBER`** — The part to inspect (must have an `_inspection_profile.json` in the library)\n- **`DRAWING_PATH`** — Supports three formats:\n  - **Single file**: `\"path/to/drawing.png\"` or `\"path/to/drawing.pdf\"` (PDFs auto-extract all pages)\n  - **List of files**: `[\"sheet1.png\", \"sheet2.png\"]`\n  - **Glob pattern**: `\"drawing_samples_batch/*_1008176_*.png\"` (expands to all matches)\n- If `DRAWING_PATH` is empty, the notebook will use the library's front view image for testing"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 2: Configuration\nPART_NUMBER = \"1008176\"  # Part number to inspect\nDRAWING_PATH = \"drawing_samples_batch/59_BASE ASSEMBLY_1008176_01.png\"  # Single file, list, or glob\n\nLIBRARY_DIR = \"400S_Sorted_Library\"     # Folder with inspection profiles\nOUTPUT_DIR = \"inspection_output\"         # Where results are saved\n\nVISION_MODEL = \"claude-sonnet-4-20250514\"  # Claude for vision analysis\nREPORT_MODEL = \"gpt-4o-mini\"               # GPT for report writing\n\n# Multi-page examples:\n# DRAWING_PATH = [\"sheet1.png\", \"sheet2.png\"]           # list of files\n# DRAWING_PATH = \"drawing_samples_batch/*_1008176_*.png\" # glob pattern\n# DRAWING_PATH = \"drawing.pdf\"                           # PDF (all pages extracted)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 3: Match part to inspection profile & load drawing\nimport glob as glob_mod\n\nlibrary = Path(LIBRARY_DIR)\noutput = Path(OUTPUT_DIR)\noutput.mkdir(parents=True, exist_ok=True)\n\n# --- Find inspection profile ---\nprofile_path = library / f\"{PART_NUMBER}_inspection_profile.json\"\nif not profile_path.exists():\n    profile_path = library / f\"{PART_NUMBER}.inspection_profile.json\"\n\nif not profile_path.exists():\n    print(f\"ERROR: No inspection profile found for part {PART_NUMBER}\")\n    print(f\"\\nAvailable profiles (first 20):\")\n    profiles = sorted(library.glob(\"*_inspection_profile.json\"))\n    for p in profiles[:20]:\n        pn = p.name.replace(\"_inspection_profile.json\", \"\")\n        print(f\"  {pn}\")\n    if len(profiles) > 20:\n        print(f\"  ... and {len(profiles) - 20} more\")\n    raise FileNotFoundError(f\"No profile for {PART_NUMBER}\")\n\nwith open(profile_path, \"r\", encoding=\"utf-8\") as f:\n    inspection_profile = json.load(f)\n\nprint(f\"Inspection profile: {profile_path.name}\")\nprint(f\"  Part:     {inspection_profile.get('part_number', 'N/A')}\")\nprint(f\"  Name:     {inspection_profile.get('part_name', 'N/A')}\")\nprint(f\"  Features: {len(inspection_profile.get('features', []))}\")\nfor feat in inspection_profile.get(\"features\", []):\n    print(f\"    - {feat.get('name', '?')} ({feat.get('type', '?')}) x{feat.get('count', 1)}\")\n\n# --- Load drawing pages ---\ndef load_single_file(path_str):\n    \"\"\"Load one file, returning a list of PIL Images (multiple for PDFs).\"\"\"\n    p = Path(path_str)\n    if p.suffix.lower() == \".pdf\":\n        import fitz\n        doc = fitz.open(str(p))\n        pages = []\n        for page in doc:\n            pix = page.get_pixmap(dpi=200)\n            pages.append(Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples))\n        doc.close()\n        return pages\n    return [Image.open(p).convert(\"RGB\")]\n\ndef load_drawing_pages(drawing_path):\n    \"\"\"Load drawing pages from a path string, list of paths, or glob pattern.\"\"\"\n    # List of paths\n    if isinstance(drawing_path, list):\n        pages = []\n        for p in drawing_path:\n            pages.extend(load_single_file(p))\n        return pages\n\n    # String — check for glob pattern\n    if isinstance(drawing_path, str) and any(c in drawing_path for c in \"*?[\"):\n        matches = sorted(glob_mod.glob(drawing_path))\n        if not matches:\n            raise FileNotFoundError(f\"Glob pattern matched no files: {drawing_path}\")\n        pages = []\n        for m in matches:\n            pages.extend(load_single_file(m))\n        return pages\n\n    # Single file path\n    return load_single_file(drawing_path)\n\nif DRAWING_PATH:\n    drawing_pages = load_drawing_pages(DRAWING_PATH)\n    print(f\"\\nDrawing: {len(drawing_pages)} page(s)\")\n    for i, pg in enumerate(drawing_pages, 1):\n        print(f\"  Page {i}: {pg.size[0]}x{pg.size[1]}\")\nelse:\n    fallback = library / f\"{PART_NUMBER}_view_front.png\"\n    if fallback.exists():\n        drawing_pages = [Image.open(fallback).convert(\"RGB\")]\n        print(f\"\\nNo DRAWING_PATH set — using front view for testing: {fallback.name}\")\n        print(f\"  NOTE: Set DRAWING_PATH to an actual engineering drawing for real inspection.\")\n    else:\n        raise FileNotFoundError(\"Set DRAWING_PATH to your engineering drawing.\")\n\n# --- Encode for API ---\ndef encode_image(img, max_dim=1568):\n    w, h = img.size\n    if max(w, h) > max_dim:\n        scale = max_dim / max(w, h)\n        img = img.resize((int(w * scale), int(h * scale)), Image.LANCZOS)\n    buf = io.BytesIO()\n    if img.mode in (\"RGBA\", \"P\"):\n        img = img.convert(\"RGB\")\n    img.save(buf, format=\"JPEG\", quality=85)\n    return base64.standard_b64encode(buf.getvalue()).decode(\"utf-8\")\n\ndrawing_b64_list = [encode_image(pg) for pg in drawing_pages]\ntotal_kb = sum(len(b) for b in drawing_b64_list) // 1024\nprint(f\"Encoded: {total_kb}KB total base64 across {len(drawing_b64_list)} page(s)\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 4: Claude Vision — inspect drawing against profile\n\nINSPECTION_SYSTEM = (\n    \"You are a senior mechanical engineering drawing inspector with 20+ years of \"\n    \"experience reading engineering drawings per ASME Y14.5. You have been given an \"\n    \"inspection profile that describes what features a part SHOULD have, where they \"\n    \"should appear, and what they should look like in each drawing view. \"\n    \"Your job is to examine the actual engineering drawing and verify every expected \"\n    \"feature is properly represented. You output ONLY valid JSON.\"\n)\n\nINSPECTION_PROMPT = \"\"\"\\\n## Inspection Profile\n\nBelow is the spatial inspection profile for part **{part_number}** ({part_name}).\nThis was generated from the 3D CAD model and describes every feature the part has,\nwhere each feature is located, and what it should look like in each drawing view.\n\n```json\n{profile_json}\n```\n\n## Your Task\n\nExamine ALL pages/sheets of the engineering drawing above and check them against the inspection profile.\nA feature may appear on ANY sheet — check all of them before marking something MISSING.\n\nFor EACH feature listed in the profile:\n1. Search the drawing for evidence of that feature (dimension callouts, hole symbols,\n   thread notes, fillet radii, chamfer specs, etc.)\n2. Determine if the feature is properly represented with correct callouts and dimensions\n3. Note any discrepancies between what the profile expects and what the drawing shows\n\nAlso check the view_expectations — does the drawing include the recommended views\nand section cuts?\n\n## Output\n\nReturn ONLY a valid JSON object (no markdown fences, no commentary):\n\n{{\n  \"part_number\": \"{part_number}\",\n  \"part_name\": \"{part_name}\",\n  \"drawing_overview\": \"Brief description of what views are present and overall impression.\",\n  \"features\": [\n    {{\n      \"name\": \"<feature name from profile>\",\n      \"type\": \"<feature type>\",\n      \"expected_count\": 1,\n      \"status\": \"PRESENT | MISSING | PARTIAL | DISCREPANT\",\n      \"found_callout\": \"<exact callout text found on drawing, or null>\",\n      \"found_on_page\": \"<page number where feature was found, or null>\",\n      \"observation\": \"<what you see or don't see for this feature>\",\n      \"severity\": \"CRITICAL | MAJOR | MINOR | INFO\"\n    }}\n  ],\n  \"view_assessment\": {{\n    \"views_present\": [\"list of drawing views identified\"],\n    \"section_cuts\": [\"list of section cuts if any\"],\n    \"missing_views\": \"any recommended views not present\",\n    \"view_notes\": \"observations about view layout and completeness\"\n  }},\n  \"gap_summary\": {{\n    \"total_features\": 0,\n    \"present\": 0,\n    \"missing\": 0,\n    \"partial\": 0,\n    \"discrepant\": 0,\n    \"critical_issues\": [\"list of critical findings\"],\n    \"overall_completeness\": \"percentage estimate\"\n  }}\n}}\n\"\"\"\n\nprofile_text = json.dumps(inspection_profile, indent=2)\nprompt = INSPECTION_PROMPT.format(\n    part_number=inspection_profile.get(\"part_number\", PART_NUMBER),\n    part_name=inspection_profile.get(\"part_name\", \"Unknown\"),\n    profile_json=profile_text,\n)\n\nnum_pages = len(drawing_b64_list)\nprint(f\"Sending to Claude ({VISION_MODEL})...\")\nprint(f\"  Profile: {len(inspection_profile.get('features', []))} features\")\nprint(f\"  Drawing: {num_pages} page(s), {total_kb}KB total\")\nprint()\n\n# Build content array: labeled images first, then text prompt\ncontent = []\nfor i, b64 in enumerate(drawing_b64_list, 1):\n    if num_pages > 1:\n        content.append({\"type\": \"text\", \"text\": f\"[PAGE {i} of {num_pages}]\"})\n    content.append({\n        \"type\": \"image\",\n        \"source\": {\n            \"type\": \"base64\",\n            \"media_type\": \"image/jpeg\",\n            \"data\": b64,\n        },\n    })\ncontent.append({\"type\": \"text\", \"text\": prompt})\n\nstart = time.time()\n\nclient = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)\n\nresponse = client.messages.create(\n    model=VISION_MODEL,\n    max_tokens=4096,\n    system=INSPECTION_SYSTEM,\n    messages=[{\"role\": \"user\", \"content\": content}],\n)\n\nraw_response = \"\"\nfor block in response.content:\n    if block.type == \"text\":\n        raw_response += block.text\n\nelapsed = time.time() - start\ntokens_in = response.usage.input_tokens\ntokens_out = response.usage.output_tokens\n\nprint(f\"Claude responded in {elapsed:.1f}s ({tokens_in:,} input + {tokens_out:,} output tokens)\")\n\n# Parse response\ntext = raw_response.strip()\nif text.startswith(\"```\"):\n    text = re.sub(r\"^```(?:json)?\\s*\", \"\", text)\n    text = re.sub(r\"\\s*```$\", \"\", text)\n\nfindings = json.loads(text)\n\ngap = findings.get(\"gap_summary\", {})\nprint(f\"\\n=== Gap Summary ===\")\nprint(f\"  Total features:  {gap.get('total_features', '?')}\")\nprint(f\"  Present:         {gap.get('present', '?')}\")\nprint(f\"  Missing:         {gap.get('missing', '?')}\")\nprint(f\"  Partial:         {gap.get('partial', '?')}\")\nprint(f\"  Discrepant:      {gap.get('discrepant', '?')}\")\nprint(f\"  Completeness:    {gap.get('overall_completeness', '?')}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "# Cell 5: Feature-by-feature findings\n\nprint(f\"{'#':>3s}  {'Status':12s} {'Severity':10s} {'Page':6s} Feature\")\nprint(\"=\" * 90)\n\nfor i, feat in enumerate(findings.get(\"features\", []), 1):\n    status = feat.get(\"status\", \"?\")\n    severity = feat.get(\"severity\", \"?\")\n    name = feat.get(\"name\", \"?\")\n    page = feat.get(\"found_on_page\", \"-\") or \"-\"\n\n    marker = {\n        \"PRESENT\": \"  OK \",\n        \"MISSING\": \" MISS\",\n        \"PARTIAL\": \" PART\",\n        \"DISCREPANT\": \" DIFF\",\n    }.get(status, \"  ?  \")\n\n    print(f\"{i:3d} [{marker}] {status:12s} {severity:10s} {str(page):6s} {name}\")\n    if feat.get(\"found_callout\"):\n        print(f\"     callout: \\\"{feat['found_callout']}\\\"\")\n    if feat.get(\"observation\"):\n        obs = feat[\"observation\"]\n        if len(obs) > 90:\n            obs = obs[:87] + \"...\"\n        print(f\"     note: {obs}\")\n\n# Critical issues\ncritical = gap.get(\"critical_issues\", [])\nif critical:\n    print(f\"\\n{'!' * 60}\")\n    print(f\"CRITICAL ISSUES ({len(critical)}):\")\n    for issue in critical:\n        print(f\"  !! {issue}\")\n    print(f\"{'!' * 60}\")\n\n# View assessment\nva = findings.get(\"view_assessment\", {})\nif va:\n    print(f\"\\n=== View Assessment ===\")\n    print(f\"  Views present: {', '.join(va.get('views_present', []))}\")\n    if va.get(\"section_cuts\"):\n        print(f\"  Section cuts:  {', '.join(va['section_cuts'])}\")\n    if va.get(\"missing_views\"):\n        print(f\"  Missing views: {va['missing_views']}\")\n    if va.get(\"view_notes\"):\n        print(f\"  Notes: {va['view_notes']}\")",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 6: GPT-4o Report\n",
    "from openai import OpenAI\n",
    "\n",
    "REPORT_SYSTEM = (\n",
    "    \"You are a quality control report writer for a precision machining company. \"\n",
    "    \"You write clear, professional inspection reports that help engineers quickly \"\n",
    "    \"understand what is wrong with an engineering drawing and what needs to be fixed. \"\n",
    "    \"Your reports are concise but thorough, with actionable recommendations.\"\n",
    ")\n",
    "\n",
    "REPORT_PROMPT = \"\"\"\\\n",
    "Write a QC inspection report based on the following automated drawing analysis.\n",
    "\n",
    "The analysis compared the engineering drawing for part **{part_number}** ({part_name})\n",
    "against its spatial inspection profile generated from the 3D CAD model.\n",
    "\n",
    "## Analysis Results\n",
    "\n",
    "```json\n",
    "{findings_json}\n",
    "```\n",
    "\n",
    "## Report Format\n",
    "\n",
    "Write a report with these sections:\n",
    "\n",
    "1. **SUMMARY** — One paragraph overview\n",
    "2. **DRAWING COMPLETENESS** — Percentage of features properly represented\n",
    "3. **CRITICAL ISSUES** — MISSING or DISCREPANT features (if any)\n",
    "4. **PARTIAL CALLOUTS** — Features visible but missing dimensions or tolerances\n",
    "5. **VIEW ASSESSMENT** — Are the right views and sections present?\n",
    "6. **RECOMMENDATIONS** — Specific actions to fix the drawing (if needed)\n",
    "\n",
    "Keep it concise and actionable. If the drawing is complete, say so clearly.\n",
    "\"\"\"\n",
    "\n",
    "oai_client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "print(f\"Generating report with {REPORT_MODEL}...\")\n",
    "start = time.time()\n",
    "\n",
    "report_response = oai_client.chat.completions.create(\n",
    "    model=REPORT_MODEL,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": REPORT_SYSTEM},\n",
    "        {\"role\": \"user\", \"content\": REPORT_PROMPT.format(\n",
    "            part_number=findings.get(\"part_number\", PART_NUMBER),\n",
    "            part_name=findings.get(\"part_name\", \"Unknown\"),\n",
    "            findings_json=json.dumps(findings, indent=2),\n",
    "        )},\n",
    "    ],\n",
    "    max_tokens=2000,\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "report_text = report_response.choices[0].message.content\n",
    "elapsed = time.time() - start\n",
    "report_tokens = report_response.usage.total_tokens if report_response.usage else 0\n",
    "\n",
    "print(f\"Report generated in {elapsed:.1f}s ({report_tokens:,} tokens)\")\n",
    "print()\n",
    "print(\"=\" * 70)\n",
    "print(report_text)\n",
    "print(\"=\" * 70)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Cell 7: Save results\n",
    "out = Path(OUTPUT_DIR)\n",
    "out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Findings JSON\n",
    "findings_path = out / f\"{PART_NUMBER}_findings.json\"\n",
    "with open(findings_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(findings, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Report markdown\n",
    "report_path = out / f\"{PART_NUMBER}_report.md\"\n",
    "with open(report_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(report_text)\n",
    "\n",
    "# Full context (for audit trail)\n",
    "context = {\n",
    "    \"part_number\": PART_NUMBER,\n",
    "    \"drawing_path\": str(DRAWING_PATH),\n",
    "    \"profile_path\": str(profile_path),\n",
    "    \"inspection_profile\": inspection_profile,\n",
    "    \"findings\": findings,\n",
    "    \"report\": report_text,\n",
    "    \"models\": {\"vision\": VISION_MODEL, \"report\": REPORT_MODEL},\n",
    "    \"tokens\": {\n",
    "        \"claude_input\": tokens_in,\n",
    "        \"claude_output\": tokens_out,\n",
    "        \"gpt_total\": report_tokens,\n",
    "    },\n",
    "}\n",
    "context_path = out / f\"{PART_NUMBER}_full_context.json\"\n",
    "with open(context_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(context, f, indent=2, ensure_ascii=False, default=str)\n",
    "\n",
    "print(f\"Results saved to {OUTPUT_DIR}/\")\n",
    "print(f\"  {findings_path.name}  — Claude's structured findings\")\n",
    "print(f\"  {report_path.name}  — QC report (markdown)\")\n",
    "print(f\"  {context_path.name}  — Full audit context\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}