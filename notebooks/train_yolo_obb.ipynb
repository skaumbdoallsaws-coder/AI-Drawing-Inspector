{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO11-OBB Finetuning for Engineering Drawing Callouts\n",
    "\n",
    "Train a YOLO11n-OBB model to detect 4 callout types:\n",
    "- **Hole** (idx 0) — diameter callouts\n",
    "- **TappedHole** (idx 1) — thread callouts\n",
    "- **Fillet** (idx 4) — radius callouts\n",
    "- **Chamfer** (idx 5) — chamfer callouts\n",
    "\n",
    "**Requirements:** A100 GPU, Roboflow API key, annotated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Install Dependencies & Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q ultralytics roboflow\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"WARNING: No GPU detected. Training will be very slow.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Clone Repo & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "REPO_DIR = \"/content/AI-Drawing-Inspector\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone https://github.com/skaumbdoallsaws-coder/AI-Drawing-Inspector.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Download Dataset from Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "\n",
    "# --- EDIT THESE VALUES ---\n",
    "ROBOFLOW_API_KEY = \"YOUR_API_KEY\"  # Replace with your key\n",
    "ROBOFLOW_WORKSPACE = \"YOUR_WORKSPACE\"  # Replace\n",
    "ROBOFLOW_PROJECT = \"ai-inspector-callout-detection\"  # Your project name\n",
    "ROBOFLOW_VERSION = 1  # Dataset version number\n",
    "# -------------------------\n",
    "\n",
    "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
    "project = rf.workspace(ROBOFLOW_WORKSPACE).project(ROBOFLOW_PROJECT)\n",
    "dataset = project.version(ROBOFLOW_VERSION).download(\"yolov8-obb\", location=\"/content/dataset\")\n",
    "\n",
    "DATASET_ROOT = \"/content/dataset\"\n",
    "print(f\"Dataset downloaded to: {DATASET_ROOT}\")\n",
    "print(f\"Train images: {len(os.listdir(os.path.join(DATASET_ROOT, 'train', 'images')))}\")\n",
    "print(f\"Val images:   {len(os.listdir(os.path.join(DATASET_ROOT, 'valid', 'images')))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Remap Class Indices\n",
    "\n",
    "Roboflow exports classes alphabetically (Chamfer=0, Fillet=1, Hole=2, TappedHole=3).\n",
    "Our pipeline uses classes.py indices (Hole=0, TappedHole=1, Fillet=4, Chamfer=5).\n",
    "This cell remaps all label files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "from ai_inspector.fine_tuning.data_generator import (\n",
    "    remap_labels,\n",
    "    ROBOFLOW_TO_CLASSES_PY,\n",
    ")\n",
    "\n",
    "print(\"Remapping class indices:\")\n",
    "print(f\"  Roboflow -> classes.py: {ROBOFLOW_TO_CLASSES_PY}\")\n",
    "print()\n",
    "\n",
    "for split in [\"train\", \"valid\", \"test\"]:\n",
    "    label_dir = os.path.join(DATASET_ROOT, split, \"labels\")\n",
    "    if os.path.isdir(label_dir):\n",
    "        result = remap_labels(label_dir, ROBOFLOW_TO_CLASSES_PY)\n",
    "        print(f\"  {split}: {result['files']} files, {result['annotations']} annotations\")\n",
    "    else:\n",
    "        print(f\"  {split}: no labels directory\")\n",
    "\n",
    "# Verify a sample\n",
    "train_labels = os.path.join(DATASET_ROOT, \"train\", \"labels\")\n",
    "sample_file = sorted(os.listdir(train_labels))[0]\n",
    "print(f\"\\nSample label ({sample_file}):\")\n",
    "with open(os.path.join(train_labels, sample_file)) as f:\n",
    "    for line in f.readlines()[:3]:\n",
    "        cls_idx = int(line.split()[0])\n",
    "        from ai_inspector.detection.classes import IDX_TO_CLASS\n",
    "        cls_name = IDX_TO_CLASS.get(cls_idx, f\"UNKNOWN({cls_idx})\")\n",
    "        print(f\"  class {cls_idx} = {cls_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Generate dataset.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_inspector.fine_tuning.data_generator import generate_dataset_yaml\n",
    "\n",
    "yaml_path = os.path.join(DATASET_ROOT, \"dataset.yaml\")\n",
    "generate_dataset_yaml(yaml_path, DATASET_ROOT)\n",
    "\n",
    "print(f\"Generated: {yaml_path}\")\n",
    "print()\n",
    "with open(yaml_path) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Train YOLO11n-OBB\n",
    "\n",
    "Drawing-safe augmentation settings:\n",
    "- No horizontal/vertical flip (text becomes unreadable)\n",
    "- No hue/saturation changes (drawings are monochrome)\n",
    "- Minimal rotation (callouts are axis-aligned)\n",
    "- Reduced mosaic probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load pretrained model\n",
    "model = YOLO(\"yolo11n-obb.pt\")\n",
    "\n",
    "# Train with drawing-safe augmentation\n",
    "results = model.train(\n",
    "    data=os.path.join(DATASET_ROOT, \"dataset.yaml\"),\n",
    "    epochs=150,\n",
    "    batch=32,\n",
    "    imgsz=1024,\n",
    "    amp=True,\n",
    "    device=0,\n",
    "    project=\"runs/obb\",\n",
    "    name=\"callout_v1\",\n",
    "    # Drawing-safe augmentation\n",
    "    flipud=0.0,        # No vertical flip\n",
    "    fliplr=0.0,        # No horizontal flip\n",
    "    hsv_h=0.0,         # No hue shift (monochrome)\n",
    "    hsv_s=0.0,         # No saturation shift\n",
    "    hsv_v=0.1,         # Tiny brightness variation\n",
    "    degrees=2.0,       # Minimal rotation (callouts are axis-aligned)\n",
    "    mosaic=0.3,        # Reduced mosaic (preserve spatial context)\n",
    "    scale=0.3,         # Moderate scale augmentation\n",
    "    translate=0.1,     # Small translation\n",
    "    # Performance\n",
    "    workers=4,\n",
    "    patience=30,       # Early stopping\n",
    "    save_period=25,    # Save checkpoint every 25 epochs\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"\\nTraining complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Validate & Print Per-Class mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best model\n",
    "best_model = YOLO(\"runs/obb/callout_v1/weights/best.pt\")\n",
    "\n",
    "# Run validation\n",
    "val_results = best_model.val(\n",
    "    data=os.path.join(DATASET_ROOT, \"dataset.yaml\"),\n",
    "    imgsz=1024,\n",
    "    batch=32,\n",
    "    device=0,\n",
    ")\n",
    "\n",
    "# Print per-class results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"mAP50:     {val_results.box.map50:.4f}\")\n",
    "print(f\"mAP50-95:  {val_results.box.map:.4f}\")\n",
    "print()\n",
    "\n",
    "# Per-class mAP50\n",
    "from ai_inspector.detection.classes import IDX_TO_CLASS\n",
    "print(\"Per-class mAP50:\")\n",
    "if hasattr(val_results.box, 'ap50') and val_results.box.ap50 is not None:\n",
    "    for i, ap in enumerate(val_results.box.ap50):\n",
    "        cls_name = IDX_TO_CLASS.get(i, f\"class_{i}\")\n",
    "        if ap > 0:\n",
    "            print(f\"  {cls_name:20s}: {ap:.4f}\")\n",
    "else:\n",
    "    print(\"  (per-class AP not available in this format)\")\n",
    "\n",
    "# Pass/Fail check\n",
    "target_map = 0.5\n",
    "if val_results.box.map50 >= target_map:\n",
    "    print(f\"\\nPASS: mAP50 ({val_results.box.map50:.4f}) >= {target_map}\")\n",
    "else:\n",
    "    print(f\"\\nBELOW TARGET: mAP50 ({val_results.box.map50:.4f}) < {target_map}\")\n",
    "    print(\"Consider: more annotations, more epochs, or larger model (yolo11s-obb.pt)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Copy Best Weights to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "# Create output directory\n",
    "drive_dir = \"/content/drive/MyDrive/AI-Inspector-Models\"\n",
    "os.makedirs(drive_dir, exist_ok=True)\n",
    "\n",
    "# Copy best weights\n",
    "src = \"runs/obb/callout_v1/weights/best.pt\"\n",
    "dst = os.path.join(drive_dir, \"callout_v1_best.pt\")\n",
    "shutil.copy2(src, dst)\n",
    "print(f\"Saved: {dst}\")\n",
    "\n",
    "# Also copy last weights as backup\n",
    "src_last = \"runs/obb/callout_v1/weights/last.pt\"\n",
    "if os.path.exists(src_last):\n",
    "    dst_last = os.path.join(drive_dir, \"callout_v1_last.pt\")\n",
    "    shutil.copy2(src_last, dst_last)\n",
    "    print(f\"Saved: {dst_last}\")\n",
    "\n",
    "# Copy training results\n",
    "results_src = \"runs/obb/callout_v1/results.csv\"\n",
    "if os.path.exists(results_src):\n",
    "    shutil.copy2(results_src, os.path.join(drive_dir, \"callout_v1_results.csv\"))\n",
    "    print(f\"Saved: callout_v1_results.csv\")\n",
    "\n",
    "print(f\"\\nAll outputs saved to: {drive_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Quick Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Pick a validation image\n",
    "val_img_dir = os.path.join(DATASET_ROOT, \"valid\", \"images\")\n",
    "test_images = sorted(os.listdir(val_img_dir))[:3]\n",
    "\n",
    "# Color map for classes\n",
    "CLASS_COLORS = {\n",
    "    0: \"#00FF00\",  # Hole - green\n",
    "    1: \"#FF6600\",  # TappedHole - orange\n",
    "    4: \"#0099FF\",  # Fillet - blue\n",
    "    5: \"#FF00FF\",  # Chamfer - magenta\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, min(3, len(test_images)), figsize=(20, 8))\n",
    "if len(test_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, img_name in zip(axes, test_images):\n",
    "    img_path = os.path.join(val_img_dir, img_name)\n",
    "    \n",
    "    # Run inference\n",
    "    results = best_model(img_path, imgsz=1024, conf=0.25)\n",
    "    \n",
    "    # Plot\n",
    "    img = Image.open(img_path)\n",
    "    ax.imshow(img, cmap=\"gray\")\n",
    "    ax.set_title(img_name[:30], fontsize=10)\n",
    "    \n",
    "    if results[0].obb is not None:\n",
    "        for obb in results[0].obb:\n",
    "            cls_id = int(obb.cls[0])\n",
    "            conf = float(obb.conf[0])\n",
    "            cls_name = IDX_TO_CLASS.get(cls_id, f\"cls{cls_id}\")\n",
    "            color = CLASS_COLORS.get(cls_id, \"#FFFFFF\")\n",
    "            \n",
    "            # Get OBB corners\n",
    "            if hasattr(obb, 'xyxyxyxy'):\n",
    "                corners = obb.xyxyxyxy[0].cpu().numpy()\n",
    "                polygon = patches.Polygon(\n",
    "                    corners, closed=True,\n",
    "                    linewidth=2, edgecolor=color, facecolor=\"none\"\n",
    "                )\n",
    "                ax.add_patch(polygon)\n",
    "                ax.text(\n",
    "                    corners[0][0], corners[0][1] - 5,\n",
    "                    f\"{cls_name} {conf:.2f}\",\n",
    "                    color=color, fontsize=8,\n",
    "                    bbox=dict(boxstyle=\"round,pad=0.2\", facecolor=\"black\", alpha=0.7)\n",
    "                )\n",
    "    \n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"inference_preview.png\", dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()\n",
    "print(\"Saved: inference_preview.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Integration Test with Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ai_inspector.pipeline import YOLOPipeline\n",
    "from ai_inspector.config import Config\n",
    "\n",
    "# Use the finetuned model\n",
    "config = Config(yolo_model_path=\"runs/obb/callout_v1/weights/best.pt\")\n",
    "pipeline = YOLOPipeline(model_path=config.yolo_model_path, config=config)\n",
    "\n",
    "# Run on a validation image\n",
    "test_img = os.path.join(val_img_dir, test_images[0])\n",
    "result = pipeline.run(test_img)\n",
    "\n",
    "print(f\"Image: {test_images[0]}\")\n",
    "print(f\"Detections: {len(result.detections)}\")\n",
    "print(f\"Callouts:   {len(result.callouts)}\")\n",
    "print()\n",
    "\n",
    "for i, callout in enumerate(result.callouts[:10]):\n",
    "    print(f\"  [{i}] {callout.get('calloutType', '?'):15s} | \"\n",
    "          f\"raw: {callout.get('raw_text', '?')[:40]}\")\n",
    "\n",
    "print(\"\\nPipeline integration: OK\" if result.callouts else \"\\nNo callouts extracted\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}